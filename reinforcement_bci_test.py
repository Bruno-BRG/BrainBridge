#!/usr/bin/env python3
"""
üéØ BCI com Aprendizado por Refor√ßo - Sequencial T0/T1/T2

PROTOCOLO DE REFOR√áO:
‚úÖ Streaming sequencial 400 em 400 (sem sobreposi√ß√£o)
‚úÖ Usa sequ√™ncia conhecida T0‚ÜíT1‚ÜíT0‚ÜíT2‚ÜíT0 (padr√£o das grava√ß√µes)
‚úÖ REFOR√áA apenas quando:
   - Predi√ß√£o √© T1 ou T2 (ignora T0/repouso)
   - Confian√ßa > 60%
‚úÖ Usa o label correto baseado na posi√ß√£o na sequ√™ncia conhecida
‚úÖ Atualiza modelo online com gradiente descendente

SEQU√äNCIA PADR√ÉO (15 ciclos):
T0(repouso) ‚Üí T1(m√£o_esq) ‚Üí T0(repouso) ‚Üí T2(m√£o_dir) ‚Üí T0(repouso) ‚Üí repeat...
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import time
import logging
from pathlib import Path
from collections import deque
import sys

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Verificar LSL
try:
    from pylsl import StreamInlet, resolve_streams, resolve_byprop
    logger.info("‚úÖ pylsl dispon√≠vel")
except ImportError:
    logger.error("‚ùå Instale: pip install pylsl")
    sys.exit(1)

# ============================================================================
# MODELOS (COPIADO DO SEQUENTIAL_BCI_TEST.PY)
# ============================================================================

class EEGNet(nn.Module):
    def __init__(self, n_channels=16, n_classes=2, n_samples=400, 
                 dropout_rate=0.25, kernel_length=64, F1=8, D=2, F2=16):
        super(EEGNet, self).__init__()
        
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.n_samples = n_samples
        
        # Bloco 1: Temporal Convolution
        self.firstconv = nn.Sequential(
            nn.Conv2d(1, F1, (1, kernel_length), padding=(0, kernel_length // 2), bias=False),
            nn.BatchNorm2d(F1)
        )
        
        # Bloco 2: Depthwise Convolution
        self.depthwiseConv = nn.Sequential(
            nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False),
            nn.BatchNorm2d(F1 * D),
            nn.ELU(),
            nn.AvgPool2d((1, 4)),
            nn.Dropout(dropout_rate)
        )
        
        # Bloco 3: Separable Convolution
        self.separableConv = nn.Sequential(
            nn.Conv2d(F1 * D, F1 * D, (1, 16), padding=(0, 8), groups=F1 * D, bias=False),
            nn.Conv2d(F1 * D, F2, 1, bias=False),
            nn.BatchNorm2d(F2),
            nn.ELU(),
            nn.AvgPool2d((1, 8)),
            nn.Dropout(dropout_rate)
        )
        
        # Classificador
        self.feature_size = self._get_conv_output_size()
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(self.feature_size, n_classes)
        )
        
    def _get_conv_output_size(self):
        with torch.no_grad():
            dummy_input = torch.zeros(1, 1, self.n_channels, self.n_samples)
            x = self.firstconv(dummy_input)
            x = self.depthwiseConv(x)
            x = self.separableConv(x)
            return x.numel()
    
    def forward(self, x):
        if len(x.shape) == 3:
            x = x.unsqueeze(1)
        
        x = self.firstconv(x)
        x = self.depthwiseConv(x)
        x = self.separableConv(x)
        x = self.classifier(x)
        return x

class AdvancedEEGNet(nn.Module):
    def __init__(self, n_channels=16, n_classes=2, n_samples=400, 
                 dropout_rate=0.25, kernel_length=64, F1=8, D=2, F2=16):
        super(AdvancedEEGNet, self).__init__()
        
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.n_samples = n_samples
        
        self.temporal_conv1 = nn.Conv2d(1, F1//2, (1, kernel_length), padding=(0, kernel_length // 2), bias=False)
        self.temporal_conv2 = nn.Conv2d(1, F1//2, (1, kernel_length//2), padding=(0, kernel_length // 4), bias=False)
        self.temporal_bn = nn.BatchNorm2d(F1)
        
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(F1, F1//4, 1),
            nn.ReLU(),
            nn.Conv2d(F1//4, F1, 1),
            nn.Sigmoid()
        )
        
        self.depthwiseConv = nn.Sequential(
            nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False),
            nn.BatchNorm2d(F1 * D),
            nn.ELU(),
            nn.AvgPool2d((1, 4)),
            nn.Dropout(dropout_rate)
        )
        
        self.separableConv = nn.Sequential(
            nn.Conv2d(F1 * D, F1 * D, (1, 16), padding=(0, 8), groups=F1 * D, bias=False),
            nn.Conv2d(F1 * D, F2, 1, bias=False),
            nn.BatchNorm2d(F2),
            nn.ELU(),
            nn.AvgPool2d((1, 8)),
            nn.Dropout(dropout_rate)
        )
        
        self.feature_enhancement = nn.Sequential(
            nn.Conv2d(F2, F2*2, 1, bias=False),
            nn.BatchNorm2d(F2*2),
            nn.ELU(),
            nn.AdaptiveAvgPool2d((1, 1))
        )
        
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(F2*2, F2),
            nn.BatchNorm1d(F2),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(F2, n_classes)
        )
    
    def forward(self, x):
        if len(x.shape) == 3:
            x = x.unsqueeze(1)
        
        temp1 = self.temporal_conv1(x)
        temp2 = self.temporal_conv2(x)
        x = torch.cat([temp1, temp2], dim=1)
        x = self.temporal_bn(x)
        
        attention = self.spatial_attention(x)
        x = x * attention
        
        x = self.depthwiseConv(x)
        x = self.separableConv(x)
        x = self.feature_enhancement(x)
        x = self.classifier(x)
        
        return x

class CustomEEGModel(nn.Module):
    def __init__(self, n_chans=16, n_outputs=2, n_times=400, sfreq=125.0, 
                 model_type='advanced', **kwargs):
        super().__init__()
        self.n_chans = n_chans
        self.n_outputs = n_outputs
        self.n_times = n_times
        self.sfreq = sfreq
        self.model_type = model_type
        
        if model_type == 'advanced':
            self.model = AdvancedEEGNet(
                n_channels=n_chans, n_classes=n_outputs, n_samples=n_times, **kwargs
            )
        else:
            self.model = EEGNet(
                n_channels=n_chans, n_classes=n_outputs, n_samples=n_times, **kwargs
            )
        
        self.is_trained = False
    
    def forward(self, x):
        return self.model(x)

# ============================================================================
# CLASSE BCI COM APRENDIZADO POR REFOR√áO
# ============================================================================

class ReinforcementBCISystem:
    def __init__(self, confidence_threshold=0.6, learning_rate=1e-5):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.optimizer = None
        self.normalizer_stats = None
        self.confidence_threshold = confidence_threshold
        self.learning_rate = learning_rate
        
        # Buffer para coleta sequencial
        self.current_buffer = []
        
        # PROTOCOLO DE SEQU√äNCIA T0/T1/T2 (padr√£o das grava√ß√µes)
        # Cada ciclo: T0 ‚Üí T1 ‚Üí T0 ‚Üí T2 ‚Üí T0 (5 buffers por ciclo)
        self.t_sequence = [0, 1, 0, 2, 0]  # T0=repouso, T1=m√£o_esq, T2=m√£o_dir
        self.current_t_index = 0  # Posi√ß√£o atual na sequ√™ncia
        self.cycle_count = 0  # Quantos ciclos completos
        
        # Estat√≠sticas de refor√ßo
        self.total_predictions = 0
        self.reinforcement_attempts = 0
        self.successful_reinforcements = 0
        self.t1_reinforcements = 0
        self.t2_reinforcements = 0
        
        # Armazenar dados para an√°lise
        self.predictions_log = []
        self.confidences_log = []
        self.true_labels_log = []
        self.reinforced_log = []
        
        # Contadores gerais
        self.total_samples_collected = 0
        
        logger.info(f"üñ•Ô∏è Device: {self.device}")
        logger.info(f"üéØ Threshold de confian√ßa: {confidence_threshold*100}%")
        logger.info(f"üìö Learning rate: {learning_rate}")
        logger.info("üîÑ Modo: REFOR√áO com sequ√™ncia T0‚ÜíT1‚ÜíT0‚ÜíT2‚ÜíT0")
    
    def get_current_true_label(self):
        """
        Retorna o label verdadeiro baseado na posi√ß√£o atual na sequ√™ncia
        T0=repouso (n√£o usado para refor√ßo), T1=0 (m√£o esq), T2=1 (m√£o dir)
        """
        current_t = self.t_sequence[self.current_t_index]
        
        if current_t == 0:  # T0 - repouso
            return None  # N√£o fazemos refor√ßo para repouso
        elif current_t == 1:  # T1 - m√£o esquerda
            return 0
        elif current_t == 2:  # T2 - m√£o direita  
            return 1
        
        return None
    
    def advance_sequence(self):
        """Avan√ßa para pr√≥xima posi√ß√£o na sequ√™ncia T"""
        self.current_t_index += 1
        
        # Se completou um ciclo (5 posi√ß√µes), resetar
        if self.current_t_index >= len(self.t_sequence):
            self.current_t_index = 0
            self.cycle_count += 1
            logger.info(f"üîÑ Ciclo {self.cycle_count} completado! Reiniciando sequ√™ncia T0‚ÜíT1‚ÜíT0‚ÜíT2‚ÜíT0")
    
    def get_current_t_info(self):
        """Retorna informa√ß√µes sobre o T atual"""
        current_t = self.t_sequence[self.current_t_index]
        t_names = {0: "T0(repouso)", 1: "T1(m√£o_esq)", 2: "T2(m√£o_dir)"}
        
        position_in_cycle = self.current_t_index + 1
        return current_t, t_names[current_t], position_in_cycle
    
    def load_model(self):
        """Carregar modelo e configurar optimizer para refor√ßo"""
        models_dir = Path("models")
        
        if not models_dir.exists() or not list(models_dir.glob("*.pt")):
            logger.error("‚ùå Nenhum modelo encontrado!")
            return False
        
        latest = max(models_dir.glob("*.pt"), key=lambda p: p.stat().st_mtime)
        logger.info(f"üìÅ Carregando: {latest.name}")
        
        try:
            checkpoint = torch.load(latest, map_location=self.device, weights_only=False)
            
            # Criar modelo
            if 'constructor_args' in checkpoint:
                args = checkpoint['constructor_args']
                self.model = CustomEEGModel(**args)
            else:
                self.model = CustomEEGModel()
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.to(self.device)
            
            # IMPORTANTE: Modelo deve estar em modo eval para predi√ß√µes (evita erro BatchNorm)
            # S√≥ colocamos em train mode durante o gradient update
            self.model.eval()
            
            # Configurar optimizer para aprendizado online
            self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
            
            # Carregar estat√≠sticas de normaliza√ß√£o
            if 'normalization_stats' in checkpoint:
                self.normalizer_stats = checkpoint['normalization_stats']
                logger.info("‚úÖ Normalizador carregado")
            
            # Info do modelo
            if 'test_accuracy' in checkpoint:
                logger.info(f"üìä Acur√°cia base: {checkpoint['test_accuracy']:.3f}")
            
            logger.info("‚úÖ Modelo carregado e pronto para REFOR√áO!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro: {e}")
            return False
    
    def find_stream(self):
        """Encontrar stream LSL (mesmo c√≥digo do sequential)"""
        logger.info("üîç Procurando streams LSL...")
        
        streams = []
        for stream_type in ['EEG', 'ExG', 'EMG']:
            try:
                found = resolve_byprop('type', stream_type, timeout=2)
                streams.extend(found)
                if found:
                    logger.info(f"  üì° {len(found)} stream(s) {stream_type}")
            except:
                pass
        
        try:
            general = resolve_streams(wait_time=3)
            streams.extend(general)
        except:
            pass
        
        if not streams:
            logger.error("‚ùå Nenhum stream encontrado!")
            return None
        
        stream = streams[0]
        logger.info(f"üîó Conectando: {stream.name()} ({stream.channel_count()} canais)")
        
        inlet = StreamInlet(stream, max_chunklen=1)
        return inlet
    
    def normalize_data(self, data):
        """Normalizar dados (mesmo c√≥digo do sequential)"""
        if self.normalizer_stats and 'median' in self.normalizer_stats and 'iqr' in self.normalizer_stats:
            try:
                median = self.normalizer_stats['median']
                iqr = self.normalizer_stats['iqr']
                
                if hasattr(median, 'numpy'):
                    median = median.numpy()
                if hasattr(iqr, 'numpy'):
                    iqr = iqr.numpy()
                
                if median.ndim > 2:
                    median = median.squeeze()
                if iqr.ndim > 2:
                    iqr = iqr.squeeze()
                
                if median.shape == (16,):
                    median = median.reshape(16, 1)
                if iqr.shape == (16,):
                    iqr = iqr.reshape(16, 1)
                
                return (data - median) / (iqr + 1e-8)
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erro na normaliza√ß√£o salva: {e}")
        
        # Fallback: z-score simples
        return (data - np.mean(data, axis=1, keepdims=True)) / (np.std(data, axis=1, keepdims=True) + 1e-8)
    
    def collect_next_400_samples(self, inlet):
        """Coletar pr√≥ximas 400 amostras sequenciais (mesmo c√≥digo do sequential)"""
        logger.info(f"üì• Coletando amostras {self.total_samples_collected + 1} at√© {self.total_samples_collected + 400}...")
        
        self.current_buffer = []
        
        while len(self.current_buffer) < 400:
            samples, _ = inlet.pull_chunk(timeout=1.0, max_samples=50)
            
            if samples:
                for sample in samples:
                    if len(self.current_buffer) >= 400:
                        break
                    
                    if len(sample) >= 16:
                        self.current_buffer.append(sample[:16])
                    else:
                        padded = sample + [0.0] * (16 - len(sample))
                        self.current_buffer.append(padded[:16])
                    
                    self.total_samples_collected += 1
            
            current = len(self.current_buffer)
            if current % 50 == 0 or current >= 400:
                percentage = (current / 400) * 100
                logger.info(f"   üìä Progresso: {current}/400 ({percentage:.1f}%)")
            
            if not samples:
                logger.warning("‚ö†Ô∏è Nenhum dado recebido - aguardando...")
                time.sleep(0.1)
        
        logger.info(f"‚úÖ Buffer completo!")
        return True
    
    def predict_and_reinforce(self, eeg_data):
        """
        Fazer predi√ß√£o E aplicar refor√ßo se crit√©rios forem atendidos
        """
        # 1. PREDI√á√ÉO
        start_time = time.time()
        
        # Normalizar
        normalized = self.normalize_data(eeg_data)
        logger.info(f"üîç Debug - EEG data shape: {eeg_data.shape}")
        logger.info(f"üîç Debug - Normalized shape: {normalized.shape}")
        
        # Para tensor - garantir formato correto (batch, channels, height, width)
        # normalized tem shape (16, 400), precisamos (1, 1, 16, 400)
        tensor = torch.from_numpy(normalized).float().unsqueeze(0).unsqueeze(0).to(self.device)
        logger.info(f"üîç Debug - Tensor shape: {tensor.shape}")
        
        # Forward pass em modo eval para BatchNorm (mas mantendo gradientes)
        self.model.eval()  # Coloca BatchNorm em eval mode
        with torch.no_grad():  # Desabilita gradientes apenas para predi√ß√£o
            output = self.model(tensor)
            probs = torch.softmax(output, dim=1)
            prediction = torch.argmax(output, dim=1).item()
            confidence = torch.max(probs, dim=1)[0].item()
        
        processing_time = time.time() - start_time
        
        # 2. VERIFICAR SE DEVE FAZER REFOR√áO
        true_label = self.get_current_true_label()
        reinforced = False
        
        # Crit√©rios para refor√ßo:
        # - True label n√£o √© None (ou seja, n√£o √© T0/repouso)
        # - Confian√ßa > threshold
        if true_label is not None and confidence > self.confidence_threshold:
            # 3. APLICAR REFOR√áO - criar novo tensor sem no_grad para gradientes
            train_tensor = torch.from_numpy(normalized).float().unsqueeze(0).unsqueeze(0).to(self.device)
            reinforced = self.apply_reinforcement(train_tensor, true_label)
        
        # 4. LOG E ESTAT√çSTICAS
        self.total_predictions += 1
        self.predictions_log.append(prediction)
        self.confidences_log.append(confidence)
        self.true_labels_log.append(true_label)
        self.reinforced_log.append(reinforced)
        
        if reinforced:
            self.successful_reinforcements += 1
            if true_label == 0:  # T1 - m√£o esquerda
                self.t1_reinforcements += 1
            elif true_label == 1:  # T2 - m√£o direita
                self.t2_reinforcements += 1
        
        return prediction, confidence, processing_time, reinforced, true_label
    
    def apply_reinforcement(self, tensor, true_label):
        """
        Aplicar refor√ßo usando backpropagation
        """
        try:
            self.reinforcement_attempts += 1
            
            logger.info(f"üîç Debug - Tensor shape no refor√ßo: {tensor.shape}")
            
            # SOLU√á√ÉO PARA BATCH SIZE: usar eval mode para BatchNorm durante forward pass
            # e apenas fazer update dos gradientes
            self.model.eval()  # Manter BatchNorm em eval mode
            
            # Zero gradients
            self.optimizer.zero_grad()
            
            # Forward pass com gradientes habilitados mas BatchNorm em eval mode
            tensor.requires_grad_(True)
            output = self.model(tensor)
            
            # Calcular loss
            true_tensor = torch.tensor([true_label], dtype=torch.long, device=self.device)
            loss = nn.CrossEntropyLoss()(output, true_tensor)
            
            # Backward pass
            loss.backward()
            
            # Update weights
            self.optimizer.step()
            
            logger.info(f"üéØ REFOR√áO aplicado! Loss: {loss.item():.4f}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erro no refor√ßo: {e}")
            return False
    
    def run_reinforcement_session(self, n_cycles=3):
        """
        Executar sess√£o com aprendizado por refor√ßo
        n_cycles: n√∫mero de ciclos completos T0‚ÜíT1‚ÜíT0‚ÜíT2‚ÜíT0 (5 predi√ß√µes por ciclo)
        """
        total_predictions = n_cycles * 5
        
        logger.info("üß† SISTEMA BCI COM APRENDIZADO POR REFOR√áO")
        logger.info("=" * 70)
        logger.info(f"üî¢ Executando {n_cycles} ciclos ({total_predictions} predi√ß√µes)")
        logger.info(f"üìä Sequ√™ncia: T0‚ÜíT1‚ÜíT0‚ÜíT2‚ÜíT0 (repouso‚Üíesq‚Üírepouso‚Üídir‚Üírepouso)")
        logger.info(f"üéØ Refor√ßo apenas em T1/T2 com confian√ßa > {self.confidence_threshold*100}%")
        logger.info(f"üìö Learning rate: {self.learning_rate}")
        logger.info("=" * 70)
        
        # 1. Carregar modelo
        if not self.load_model():
            return
        
        # 2. Conectar LSL
        inlet = self.find_stream()
        if not inlet:
            return
        
        # 3. Executar predi√ß√µes com refor√ßo
        try:
            prediction_count = 0
            
            for cycle in range(n_cycles):
                logger.info(f"\nüîÑ CICLO {cycle + 1}/{n_cycles}")
                logger.info("=" * 50)
                
                # 5 predi√ß√µes por ciclo (T0‚ÜíT1‚ÜíT0‚ÜíT2‚ÜíT0)
                for step in range(5):
                    prediction_count += 1
                    current_t, t_name, position = self.get_current_t_info()
                    
                    logger.info(f"\nüß† PREDI√á√ÉO #{prediction_count}/{total_predictions}")
                    logger.info(f"üìç Posi√ß√£o: {position}/5 no ciclo {cycle + 1}")
                    logger.info(f"üè∑Ô∏è Esperado: {t_name}")
                    logger.info("-" * 40)
                    
                    # Coletar dados
                    if not self.collect_next_400_samples(inlet):
                        logger.error("‚ùå Falha na coleta")
                        return
                    
                    # Converter para formato do modelo
                    data = np.array(self.current_buffer).T  # (16, 400)
                    
                    # Predi√ß√£o + Refor√ßo
                    pred, conf, proc_time, reinforced, true_label = self.predict_and_reinforce(data)
                    
                    # Log da predi√ß√£o
                    pred_name = "M√£o Esquerda" if pred == 0 else "M√£o Direita"
                    logger.info(f"üéØ Predi√ß√£o: {pred_name}")
                    logger.info(f"üìä Confian√ßa: {conf:.3f}")
                    logger.info(f"‚ö° Processamento: {proc_time*1000:.1f}ms")
                    
                    # Log do refor√ßo
                    if current_t == 0:  # T0 - repouso
                        logger.info(f"üò¥ T0 (repouso) - SEM refor√ßo")
                    else:
                        if reinforced:
                            logger.info(f"‚úÖ REFOR√áO aplicado! (confian√ßa {conf:.3f} > {self.confidence_threshold})")
                        else:
                            logger.info(f"‚ùå Sem refor√ßo (confian√ßa {conf:.3f} < {self.confidence_threshold})")
                    
                    # Avan√ßar na sequ√™ncia
                    self.advance_sequence()
                    
                    # Pequena pausa
                    if prediction_count < total_predictions:
                        time.sleep(0.5)
        
        except KeyboardInterrupt:
            logger.info("\n‚èπÔ∏è Sess√£o interrompida pelo usu√°rio")
        
        # Resultados finais
        self.print_reinforcement_results()
    
    def print_reinforcement_results(self):
        """Imprimir resultados da sess√£o de refor√ßo"""
        logger.info("\n" + "=" * 80)
        logger.info("üìä RESULTADOS DA SESS√ÉO DE APRENDIZADO POR REFOR√áO")
        logger.info("=" * 80)
        
        if not self.predictions_log:
            logger.info("‚ùå Nenhuma predi√ß√£o realizada")
            return
        
        # Estat√≠sticas gerais
        total_preds = len(self.predictions_log)
        left_preds = self.predictions_log.count(0)
        right_preds = self.predictions_log.count(1)
        
        logger.info(f"üî¢ Total de predi√ß√µes: {total_preds}")
        logger.info(f"üì• Amostras coletadas: {self.total_samples_collected}")
        logger.info(f"‚è±Ô∏è Tempo de dados: {self.total_samples_collected/125:.1f}s @ 125Hz")
        logger.info(f"üîÑ Ciclos completados: {self.cycle_count}")
        
        # Distribui√ß√£o de predi√ß√µes
        logger.info(f"\nüìà Distribui√ß√£o de predi√ß√µes:")
        logger.info(f"üëà M√£o Esquerda: {left_preds} ({left_preds/total_preds*100:.1f}%)")
        logger.info(f"üëâ M√£o Direita: {right_preds} ({right_preds/total_preds*100:.1f}%)")
        
        # Estat√≠sticas de refor√ßo
        logger.info(f"\nüéØ Estat√≠sticas de refor√ßo:")
        logger.info(f"üîÑ Tentativas de refor√ßo: {self.reinforcement_attempts}")
        logger.info(f"‚úÖ Refor√ßos bem-sucedidos: {self.successful_reinforcements}")
        logger.info(f"üëà Refor√ßos T1 (m√£o esq): {self.t1_reinforcements}")
        logger.info(f"üëâ Refor√ßos T2 (m√£o dir): {self.t2_reinforcements}")
        
        if self.reinforcement_attempts > 0:
            success_rate = (self.successful_reinforcements / self.reinforcement_attempts) * 100
            logger.info(f"üìä Taxa de sucesso do refor√ßo: {success_rate:.1f}%")
        
        # Confian√ßa m√©dia
        if self.confidences_log:
            avg_conf = np.mean(self.confidences_log)
            min_conf = np.min(self.confidences_log)
            max_conf = np.max(self.confidences_log)
            logger.info(f"\nüéØ Confian√ßa: {avg_conf:.3f} (min: {min_conf:.3f}, max: {max_conf:.3f})")
            
            # Confian√ßa por tipo de predi√ß√£o
            above_threshold = sum(1 for c in self.confidences_log if c > self.confidence_threshold)
            logger.info(f"üìà Predi√ß√µes > threshold ({self.confidence_threshold*100}%): {above_threshold}/{total_preds} ({above_threshold/total_preds*100:.1f}%)")
        
        # An√°lise por tipo de T
        logger.info(f"\nüìä An√°lise por tipo de evento:")
        t0_count = t1_count = t2_count = 0
        t0_reinforced = t1_reinforced = t2_reinforced = 0
        
        for i, (true_label, reinforced) in enumerate(zip(self.true_labels_log, self.reinforced_log)):
            if true_label is None:  # T0
                t0_count += 1
            elif true_label == 0:  # T1
                t1_count += 1
                if reinforced:
                    t1_reinforced += 1
            elif true_label == 1:  # T2
                t2_count += 1
                if reinforced:
                    t2_reinforced += 1
        
        logger.info(f"üò¥ T0 (repouso): {t0_count} eventos (refor√ßo n√£o aplicado)")
        if t1_count > 0:
            logger.info(f"üëà T1 (m√£o esq): {t1_count} eventos, {t1_reinforced} refor√ßados ({t1_reinforced/t1_count*100:.1f}%)")
        if t2_count > 0:
            logger.info(f"üëâ T2 (m√£o dir): {t2_count} eventos, {t2_reinforced} refor√ßados ({t2_reinforced/t2_count*100:.1f}%)")

def main():
    print("""
üß† BCI com Aprendizado por Refor√ßo
==================================

PROTOCOLO:
‚úÖ Streaming sequencial 400 em 400 (SEM sobreposi√ß√£o)  
‚úÖ Sequ√™ncia conhecida: T0‚ÜíT1‚ÜíT0‚ÜíT2‚ÜíT0 (padr√£o das grava√ß√µes)
‚úÖ Refor√ßo APENAS quando:
   - Evento √© T1 ou T2 (ignora T0/repouso)
   - Confian√ßa > 60%
‚úÖ Usa label correto baseado na posi√ß√£o na sequ√™ncia
‚úÖ Atualiza modelo online com gradiente descendente

EXEMPLO DE USO:
- 3 ciclos = 15 predi√ß√µes
- Cada ciclo: T0‚ÜíT1‚ÜíT0‚ÜíT2‚ÜíT0
- Refor√ßo aplicado apenas em T1/T2 com alta confian√ßa
""")
    
    # Criar sistema
    bci = ReinforcementBCISystem(confidence_threshold=0.6, learning_rate=1e-5)
    
    # Executar sess√£o (3 ciclos = 15 predi√ß√µes)
    bci.run_reinforcement_session(n_cycles=3)

if __name__ == "__main__":
    main()
