{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725a5162",
   "metadata": {
    "id": "725a5162"
   },
   "source": [
    "# BCI Training Pipeline - EEGNet Personalizada\n",
    "\n",
    "Pipeline de treinamento para BCI usando CNN personalizada baseada no EEGNet:\n",
    "\n",
    "1. **EEGNet Personalizado**: Implementação própria PyTorch\n",
    "2. **Pipeline de Treinamento**: Cross-validation e early stopping  \n",
    "3. **Normalização Robusta**: Tratamento de outliers\n",
    "4. **Dados OpenBCI**: Suporte para CSV da OpenBCI GUI\n",
    "5. **Inferência em Tempo Real**: Compatível com sistema LSL\n",
    "\n",
    "## 🎯 Objetivo: CNN otimizada para BCI em tempo real (sem braindecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "y9I7ySM2Ag5G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9I7ySM2Ag5G",
    "outputId": "7517a75c-8288-4748-e176-2c42554b1e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️ Device: cpu\n",
      "🐍 PyTorch version: 2.7.1+cpu\n",
      "📂 Projeto: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\n",
      "📊 Dados: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\EndUser\\eeg_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0\n",
      "🤖 Modelos: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\n",
      "✅ Configurações básicas carregadas!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS E CONFIGURAÇÕES BÁSICAS ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from collections import deque\n",
    "from scipy import signal\n",
    "import mne\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Verificar device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🖥️ Device: {device}\")\n",
    "print(f\"🐍 PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Configurar paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_PATH = PROJECT_ROOT / \"EndUser\" / \"eeg_data\" / \"MNE-eegbci-data\" / \"files\" / \"eegmmidb\" / \"1.0.0\"\n",
    "MODELS_PATH = PROJECT_ROOT / \"models\"\n",
    "RESULTS_PATH = PROJECT_ROOT / \"results\"\n",
    "\n",
    "# Criar diretórios se não existirem\n",
    "MODELS_PATH.mkdir(exist_ok=True)\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"📂 Projeto: {PROJECT_ROOT}\")\n",
    "print(f\"📊 Dados: {DATA_PATH}\")\n",
    "print(f\"🤖 Modelos: {MODELS_PATH}\")\n",
    "print(\"✅ Configurações básicas carregadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021874a4",
   "metadata": {
    "id": "021874a4"
   },
   "source": [
    "## 1. Setup Inicial no Google Colab\n",
    "\n",
    "Vamos instalar as dependências e configurar o ambiente adequadamente.\n",
    "\n",
    "# 1. Modelo EEGNet Personalizado\n",
    "\n",
    "Implementação própria do EEGNet usando apenas PyTorch:\n",
    "\n",
    "- **Depthwise Separable Convolutions**: Reduz parâmetros\n",
    "- **Temporal e Spatial Filtering**: Especializado para EEG  \n",
    "- **Dropout e Batch Normalization**: Regularização\n",
    "- **Arquitetura Flexível**: Adaptável para diferentes configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecdd2a3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ecdd2a3e",
    "outputId": "33f9fb43-5694-4494-930c-955e103ec0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Instalando dependências necessárias...\n",
      "Requirement already satisfied: mne in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: torch in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.10.3)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (2.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (25.0)\n",
      "Requirement already satisfied: pooch>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (2.32.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.6.15)\n",
      "Requirement already satisfied: mne in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: torch in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.10.3)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (2.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (25.0)\n",
      "Requirement already satisfied: pooch>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (2.32.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.6.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.16.0)\n",
      "Requirement already satisfied: jupyter in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scipy) (2.3.1)\n",
      "Requirement already satisfied: notebook in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (7.4.3)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (8.1.7)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (4.4.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (9.3.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipykernel->jupyter) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets->jupyter) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets->jupyter) (3.0.15)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-console->jupyter) (3.0.51)\n",
      "Requirement already satisfied: pygments in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-console->jupyter) (2.19.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (2.16.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (80.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (310)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.15)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.24.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (4.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.25.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fqdn in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20250516)\n",
      "✅ Dependências instaladas!\n",
      "💻 Executando localmente\n",
      "✅ EEGNet criado: 1,746 parâmetros\n",
      "✅ Teste: torch.Size([2, 16, 400]) -> torch.Size([2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# === INSTALAÇÃO DE DEPENDÊNCIAS ===\n",
    "print(\"🔧 Instalando dependências necessárias...\")\n",
    "\n",
    "# Instalar apenas dependências científicas essenciais (sem braindecode)\n",
    "!pip install mne torch torchvision torchaudio\n",
    "!pip install scikit-learn pandas numpy matplotlib seaborn\n",
    "!pip install scipy jupyter\n",
    "\n",
    "print(\"✅ Dependências instaladas!\")\n",
    "\n",
    "# Verificar se está no Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"📱 Executando no Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"💻 Executando localmente\")\n",
    "\n",
    "# === MODELO EEGNET PERSONALIZADO ===\n",
    "class EEGNet(nn.Module):\n",
    "    \"\"\"Implementação compacta do EEGNet para BCI\"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=16, n_classes=2, n_samples=400, \n",
    "                 dropout_rate=0.25, kernel_length=64, F1=8, D=2, F2=16):\n",
    "        super(EEGNet, self).__init__()\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "        # Bloco 1: Temporal Convolution\n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, F1, (1, kernel_length), padding=(0, kernel_length // 2), bias=False),\n",
    "            nn.BatchNorm2d(F1)\n",
    "        )\n",
    "        \n",
    "        # Bloco 2: Depthwise Convolution (Spatial filtering)\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False),\n",
    "            nn.BatchNorm2d(F1 * D),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Bloco 3: Separable Convolution\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(F1 * D, F1 * D, (1, 16), padding=(0, 8), groups=F1 * D, bias=False),\n",
    "            nn.Conv2d(F1 * D, F2, 1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Classificador\n",
    "        self.feature_size = self._get_conv_output_size()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.feature_size, n_classes)\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        print(f\"✅ EEGNet criado: {sum(p.numel() for p in self.parameters()):,} parâmetros\")\n",
    "    \n",
    "    def _get_conv_output_size(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, self.n_channels, self.n_samples)\n",
    "            x = self.firstconv(dummy_input)\n",
    "            x = self.depthwiseConv(x)\n",
    "            x = self.separableConv(x)\n",
    "            return x.numel()\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)  # (batch, channels, samples) -> (batch, 1, channels, samples)\n",
    "        \n",
    "        x = self.firstconv(x)\n",
    "        x = self.depthwiseConv(x)\n",
    "        x = self.separableConv(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# === WRAPPER PARA COMPATIBILIDADE ===\n",
    "class CustomEEGModel(nn.Module):\n",
    "    def __init__(self, n_chans=16, n_outputs=2, n_times=400, sfreq=125.0, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_chans = n_chans\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_times = n_times\n",
    "        self.sfreq = sfreq\n",
    "        \n",
    "        self.model = EEGNet(n_channels=n_chans, n_classes=n_outputs, n_samples=n_times)\n",
    "        self.model_type = \"CustomEEGNet\"\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def save_checkpoint(self, filepath, **kwargs):\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'model_type': self.model_type,\n",
    "            'constructor_args': {\n",
    "                'n_chans': self.n_chans,\n",
    "                'n_outputs': self.n_outputs,\n",
    "                'n_times': self.n_times,\n",
    "                'sfreq': self.sfreq\n",
    "            },\n",
    "            'is_trained': self.is_trained,\n",
    "            **kwargs\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        print(f\"✅ Modelo salvo: {filepath}\")\n",
    "\n",
    "# Teste do modelo\n",
    "test_model = CustomEEGModel()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(2, 16, 400)\n",
    "    test_output = test_model(test_input)\n",
    "    print(f\"✅ Teste: {test_input.shape} -> {test_output.shape}\")\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e4587fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e4587fa",
    "outputId": "e22d80a4-c3c3-4657-f57b-6a3b4eebd828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports básicos carregados!\n",
      "📥 Gerando dados sintéticos para demonstração...\n",
      "✅ Dados carregados: (200, 16, 400)\n",
      "🎯 Classes: {np.int32(0): np.int64(100), np.int32(1): np.int64(100)}\n",
      "👥 Sujeitos: 5\n",
      "✅ Classes e normalização implementadas!\n"
     ]
    }
   ],
   "source": [
    "# === IMPLEMENTAÇÃO INLINE DAS CLASSES BASE ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from typing import Optional, List, Tuple, Dict, Union\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "import mne\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✅ Imports básicos carregados!\")\n",
    "\n",
    "# === CARREGAMENTO DE DADOS E NORMALIZAÇÃO ===\n",
    "class RobustEEGNormalizer:\n",
    "    \"\"\"Normalizador robusto para dados EEG\"\"\"\n",
    "    \n",
    "    def __init__(self, method='robust_zscore', outlier_threshold=3.0):\n",
    "        self.method = method\n",
    "        self.outlier_threshold = outlier_threshold\n",
    "        self.stats = {}\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # Garantir formato 3D (trials, channels, time)\n",
    "        if len(X.shape) == 2:\n",
    "            X = X.reshape(X.shape[0], 16, -1)\n",
    "        \n",
    "        # Tratar outliers usando IQR\n",
    "        Q1 = np.percentile(X, 25, axis=(0, 2), keepdims=True)\n",
    "        Q3 = np.percentile(X, 75, axis=(0, 2), keepdims=True)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - self.outlier_threshold * IQR\n",
    "        upper = Q3 + self.outlier_threshold * IQR\n",
    "        X = np.clip(X, lower, upper)\n",
    "        \n",
    "        # Calcular estatísticas por canal\n",
    "        self.stats['median'] = np.median(X, axis=(0, 2), keepdims=True)\n",
    "        self.stats['iqr'] = IQR + 1e-8\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Deve ajustar antes de transformar\")\n",
    "        \n",
    "        original_shape = X.shape\n",
    "        if len(X.shape) == 2:\n",
    "            X = X.reshape(X.shape[0], 16, -1)\n",
    "        \n",
    "        X_norm = (X - self.stats['median']) / self.stats['iqr']\n",
    "        \n",
    "        if len(original_shape) == 2:\n",
    "            X_norm = X_norm.reshape(original_shape)\n",
    "        return X_norm\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return self.stats.copy()\n",
    "\n",
    "# === DATASET PYTORCH ===\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, windows, labels, augment=False):\n",
    "        self.windows = torch.from_numpy(windows).float()\n",
    "        self.labels = torch.from_numpy(labels).long()\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        window = self.windows[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.augment and torch.rand(1) < 0.3:\n",
    "            # Adicionar ruído leve para augmentação\n",
    "            noise = torch.randn_like(window) * 0.01\n",
    "            window = window + noise\n",
    "        \n",
    "        return window, label\n",
    "\n",
    "# === CARREGAR DADOS ===\n",
    "def load_openbci_csv(file_path, sfreq=125):\n",
    "    \"\"\"Carrega arquivo CSV da OpenBCI\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, comment='%')\n",
    "        eeg_cols = [col for col in df.columns if 'EXG Channel' in col]\n",
    "        \n",
    "        if len(eeg_cols) == 0:\n",
    "            return None\n",
    "        \n",
    "        data = df[eeg_cols].T.to_numpy() * 1e-6  # µV -> V\n",
    "        info = mne.create_info(ch_names=eeg_cols, sfreq=sfreq, ch_types='eeg')\n",
    "        raw = mne.io.RawArray(data, info, verbose=False)\n",
    "        \n",
    "        # Adicionar anotações T1/T2\n",
    "        if 'Annotations' in df.columns:\n",
    "            onsets = df.index.to_numpy() / sfreq\n",
    "            for onset, annot in zip(onsets, df['Annotations'].astype(str)):\n",
    "                if annot.startswith('T'):\n",
    "                    raw.annotations.append(onset, 0, annot)\n",
    "        \n",
    "        return raw\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro ao carregar {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Gerar dados sintéticos para demonstração (substitua pela função de carregamento real)\n",
    "print(\"📥 Gerando dados sintéticos para demonstração...\")\n",
    "n_trials, n_channels, n_samples = 200, 16, 400\n",
    "np.random.seed(42)\n",
    "\n",
    "windows = np.random.randn(n_trials, n_channels, n_samples) * 0.1\n",
    "labels = np.random.randint(0, 2, n_trials)\n",
    "subject_ids = np.random.randint(1, 6, n_trials)\n",
    "\n",
    "# Adicionar padrões específicos por classe\n",
    "for i in range(n_trials):\n",
    "    if labels[i] == 0:  # Mão esquerda\n",
    "        windows[i, :8, 100:150] += 0.05 * np.sin(np.linspace(0, 4*np.pi, 50))\n",
    "    else:  # Mão direita\n",
    "        windows[i, 8:, 150:200] += 0.05 * np.sin(np.linspace(0, 4*np.pi, 50))\n",
    "\n",
    "print(f\"✅ Dados carregados: {windows.shape}\")\n",
    "print(f\"🎯 Classes: {dict(zip(*np.unique(labels, return_counts=True)))}\")\n",
    "print(f\"👥 Sujeitos: {len(np.unique(subject_ids))}\")\n",
    "\n",
    "print(\"✅ Classes e normalização implementadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a7fe101",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a7fe101",
    "outputId": "04ea0cdc-4a63-4d5b-8552-76dae598e233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ UniversalEEGNormalizer implementado!\n",
      "⚙️ Parâmetros: {'n_folds': 5, 'n_epochs': 30, 'batch_size': 16, 'learning_rate': 0.001, 'patience': 10}\n",
      "🎯 Pronto para treinamento!\n"
     ]
    }
   ],
   "source": [
    "# === UNIVERSAL EEG NORMALIZER ===\n",
    "class UniversalEEGNormalizer:\n",
    "    \"\"\"Normalizador universal para dados EEG\"\"\"\n",
    "\n",
    "    def __init__(self, method: str = 'zscore', mode: str = 'training'):\n",
    "        self.method = method\n",
    "        self.mode = mode\n",
    "        self.global_stats = {}\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def _ensure_3d(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Garantir que dados estejam em 3D (n_samples, n_channels, n_timepoints)\"\"\"\n",
    "        if len(data.shape) == 2:\n",
    "            n_samples, n_features = data.shape\n",
    "            if n_features % 16 == 0:  # Assumir 16 canais\n",
    "                n_channels = 16\n",
    "                n_timepoints = n_features // n_channels\n",
    "                data = data.reshape(n_samples, n_channels, n_timepoints)\n",
    "            else:\n",
    "                data = data[:, np.newaxis, :]\n",
    "        elif len(data.shape) == 1:\n",
    "            data = data[np.newaxis, np.newaxis, :]\n",
    "        return data\n",
    "\n",
    "    def fit(self, data: np.ndarray):\n",
    "        \"\"\"Ajustar normalizador aos dados\"\"\"\n",
    "        data_3d = self._ensure_3d(data)\n",
    "\n",
    "        if self.method == 'zscore':\n",
    "            self.global_stats['mean'] = np.mean(data_3d, axis=(0, 2), keepdims=True)\n",
    "            self.global_stats['std'] = np.std(data_3d, axis=(0, 2), keepdims=True)\n",
    "            self.global_stats['std'] = np.where(self.global_stats['std'] == 0, 1.0, self.global_stats['std'])\n",
    "\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transformar dados\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Normalizador deve ser ajustado antes da transformação\")\n",
    "\n",
    "        original_shape = data.shape\n",
    "        data_3d = self._ensure_3d(data)\n",
    "\n",
    "        if self.method == 'zscore':\n",
    "            normalized = (data_3d - self.global_stats['mean']) / self.global_stats['std']\n",
    "\n",
    "        # Restaurar forma original\n",
    "        if len(original_shape) == 2:\n",
    "            return normalized.reshape(original_shape[0], -1)\n",
    "        elif len(original_shape) == 1:\n",
    "            return normalized.flatten()\n",
    "        return normalized\n",
    "\n",
    "    def fit_transform(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Ajustar e transformar em um passo\"\"\"\n",
    "        return self.fit(data).transform(data)\n",
    "\n",
    "print(\"✅ UniversalEEGNormalizer implementado!\")\n",
    "\n",
    "# === PIPELINE DE TREINAMENTO SIMPLIFICADO ===\n",
    "def train_eegnet_model(windows, labels, subject_ids, params):\n",
    "    \"\"\"Pipeline completo de treinamento do modelo EEGNet\"\"\"\n",
    "    \n",
    "    print(\"🚀 Iniciando treinamento...\")\n",
    "    \n",
    "    # Normalização\n",
    "    normalizer = RobustEEGNormalizer()\n",
    "    windows_norm = normalizer.fit_transform(windows)\n",
    "    print(f\"✅ Normalização: média={np.mean(windows_norm):.4f}, std={np.std(windows_norm):.4f}\")\n",
    "    \n",
    "    # Split treino/teste\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        windows_norm, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    kfold = KFold(n_splits=params.get('n_folds', 5), shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    best_model_state = None\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_val), 1):\n",
    "        print(f\"\\n📁 Fold {fold}\")\n",
    "        \n",
    "        # Dados do fold\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        # DataLoaders\n",
    "        train_dataset = EEGDataset(X_train, y_train, augment=True)\n",
    "        val_dataset = EEGDataset(X_val, y_val, augment=False)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=params.get('batch_size', 16), shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=params.get('batch_size', 16), shuffle=False)\n",
    "        \n",
    "        # Modelo\n",
    "        model = CustomEEGModel(\n",
    "            n_chans=windows.shape[1],\n",
    "            n_outputs=len(np.unique(labels)),\n",
    "            n_times=windows.shape[2]\n",
    "        ).to(device)\n",
    "        \n",
    "        # Otimizador\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params.get('learning_rate', 1e-3))\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Treinamento\n",
    "        best_fold_val_acc = 0.0\n",
    "        patience_count = 0\n",
    "        \n",
    "        for epoch in range(params.get('n_epochs', 30)):\n",
    "            # Treino\n",
    "            model.train()\n",
    "            train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "            \n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += batch_y.size(0)\n",
    "                train_correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            # Validação\n",
    "            model.eval()\n",
    "            val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                    outputs = model(batch_x)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += batch_y.size(0)\n",
    "                    val_correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            train_acc = train_correct / train_total\n",
    "            val_acc = val_correct / val_total\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_acc > best_fold_val_acc:\n",
    "                best_fold_val_acc = val_acc\n",
    "                patience_count = 0\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_count += 1\n",
    "                if patience_count >= params.get('patience', 10):\n",
    "                    break\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"   Época {epoch+1}: Train {train_acc:.3f} | Val {val_acc:.3f}\")\n",
    "        \n",
    "        fold_accuracies.append(best_fold_val_acc)\n",
    "        print(f\"   ✅ Fold {fold} concluído - Val Acc: {best_fold_val_acc:.4f}\")\n",
    "    \n",
    "    # Estatísticas CV\n",
    "    cv_mean = np.mean(fold_accuracies)\n",
    "    cv_std = np.std(fold_accuracies)\n",
    "    print(f\"\\n📊 CV: {cv_mean:.4f} ± {cv_std:.4f}\")\n",
    "    \n",
    "    # Teste final\n",
    "    if best_model_state is not None:\n",
    "        final_model = CustomEEGModel(\n",
    "            n_chans=windows.shape[1],\n",
    "            n_outputs=len(np.unique(labels)),\n",
    "            n_times=windows.shape[2]\n",
    "        ).to(device)\n",
    "        final_model.load_state_dict(best_model_state)\n",
    "        final_model.eval()\n",
    "        \n",
    "        test_dataset = EEGDataset(X_test, y_test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        test_correct = test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = final_model(batch_x)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += batch_y.size(0)\n",
    "                test_correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        test_acc = test_correct / test_total\n",
    "        print(f\"🎯 Teste final: {test_acc:.4f}\")\n",
    "    else:\n",
    "        test_acc = 0.0\n",
    "        final_model = None\n",
    "    \n",
    "    results = {\n",
    "        'model_state_dict': best_model_state,\n",
    "        'cv_mean': cv_mean,\n",
    "        'cv_std': cv_std,\n",
    "        'test_accuracy': test_acc,\n",
    "        'normalization_stats': normalizer.get_stats(),\n",
    "        'model_params': {\n",
    "            'n_chans': windows.shape[1],\n",
    "            'n_outputs': len(np.unique(labels)),\n",
    "            'n_times': windows.shape[2],\n",
    "            'sfreq': 125.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results, final_model\n",
    "\n",
    "# === CONFIGURAÇÃO E EXECUÇÃO ===\n",
    "training_params = {\n",
    "    'n_folds': 5,\n",
    "    'n_epochs': 30,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-3,\n",
    "    'patience': 10\n",
    "}\n",
    "\n",
    "print(\"⚙️ Parâmetros:\", training_params)\n",
    "print(\"🎯 Pronto para treinamento!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bec4ebbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bec4ebbc",
    "outputId": "37963b05-791a-4db7-e486-c99863101af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testando modelos...\n",
      "✅ EEGNet criado: 1,746 parâmetros\n",
      "✅ Modelo EEGNet inicializado\n",
      "📊 Parâmetros totais: 1,746\n",
      "✅ EEGNet Básico: torch.Size([2, 16, 400]) -> torch.Size([2, 2])\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "✅ EEGNet Avançado: torch.Size([2, 16, 400]) -> torch.Size([2, 2])\n",
      "\n",
      "📊 Comparação de Modelos:\n",
      "   - EEGNet Básico: 1,746 parâmetros\n",
      "   - EEGNet Avançado: 2,444 parâmetros\n",
      "   - Diferença: +698 parâmetros\n",
      "\n",
      "🎯 Modelos EEGNet personalizados prontos para treinamento!\n",
      "✅ Implementação 100% PyTorch sem dependências externas!\n",
      "🚀 INICIANDO TREINAMENTO...\n",
      "🚀 Iniciando treinamento...\n",
      "✅ Normalização: média=-0.0001, std=0.7410\n",
      "\n",
      "📁 Fold 1\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   Época 10: Train 0.695 | Val 0.781\n",
      "   Época 10: Train 0.695 | Val 0.781\n",
      "   Época 20: Train 0.922 | Val 0.844\n",
      "   Época 20: Train 0.922 | Val 0.844\n",
      "   ✅ Fold 1 concluído - Val Acc: 0.8750\n",
      "\n",
      "📁 Fold 2\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   ✅ Fold 1 concluído - Val Acc: 0.8750\n",
      "\n",
      "📁 Fold 2\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   Época 10: Train 0.695 | Val 0.719\n",
      "   Época 10: Train 0.695 | Val 0.719\n",
      "   Época 20: Train 0.875 | Val 0.844\n",
      "   Época 20: Train 0.875 | Val 0.844\n",
      "   ✅ Fold 2 concluído - Val Acc: 0.9062\n",
      "\n",
      "📁 Fold 3\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   ✅ Fold 2 concluído - Val Acc: 0.9062\n",
      "\n",
      "📁 Fold 3\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   Época 10: Train 0.641 | Val 0.562\n",
      "   Época 10: Train 0.641 | Val 0.562\n",
      "   ✅ Fold 3 concluído - Val Acc: 0.6562\n",
      "\n",
      "📁 Fold 4\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   ✅ Fold 3 concluído - Val Acc: 0.6562\n",
      "\n",
      "📁 Fold 4\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   Época 10: Train 0.578 | Val 0.688\n",
      "   Época 10: Train 0.578 | Val 0.688\n",
      "   Época 20: Train 0.812 | Val 0.844\n",
      "   Época 20: Train 0.812 | Val 0.844\n",
      "   Época 30: Train 0.961 | Val 0.969\n",
      "   ✅ Fold 4 concluído - Val Acc: 0.9688\n",
      "\n",
      "📁 Fold 5\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   Época 30: Train 0.961 | Val 0.969\n",
      "   ✅ Fold 4 concluído - Val Acc: 0.9688\n",
      "\n",
      "📁 Fold 5\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   Época 10: Train 0.688 | Val 0.500\n",
      "   ✅ Fold 5 concluído - Val Acc: 0.7188\n",
      "\n",
      "📊 CV: 0.8250 ± 0.1179\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "   Época 10: Train 0.688 | Val 0.500\n",
      "   ✅ Fold 5 concluído - Val Acc: 0.7188\n",
      "\n",
      "📊 CV: 0.8250 ± 0.1179\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "🎯 Teste final: 0.9750\n",
      "\n",
      "🎉 TREINAMENTO CONCLUÍDO!\n",
      "📊 CV: 0.8250 ± 0.1179\n",
      "🎯 Teste: 0.9750\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "✅ Modelo salvo: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\\custom_eegnet_1751259706.pt\n",
      "💾 Modelo salvo: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\\custom_eegnet_1751259706.pt\n",
      "🎯 Teste final: 0.9750\n",
      "\n",
      "🎉 TREINAMENTO CONCLUÍDO!\n",
      "📊 CV: 0.8250 ± 0.1179\n",
      "🎯 Teste: 0.9750\n",
      "✅ AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - Parâmetros: 2,444\n",
      "✅ Modelo AdvancedEEGNet inicializado\n",
      "📊 Parâmetros totais: 2,444\n",
      "✅ Modelo salvo: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\\custom_eegnet_1751259706.pt\n",
      "💾 Modelo salvo: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\\custom_eegnet_1751259706.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Visualização salva: custom_eegnet_1751259706_results.png\n",
      "\n",
      "✅ PIPELINE CONCLUÍDO!\n",
      "🎯 Para usar no sistema LSL:\n",
      "   1. Copie o caminho do modelo salvo\n",
      "   2. Execute: python test_lsl_to_prediction_cycle.py\n",
      "   3. Modelo compatível com inferência em tempo real\n"
     ]
    }
   ],
   "source": [
    "# === IMPLEMENTAÇÃO CNN AVANÇADA BASEADA NO EEGNET ===\n",
    "class AdvancedEEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN avançada baseada no EEGNet com melhorias específicas para BCI\n",
    "    \n",
    "    Melhorias em relação ao EEGNet básico:\n",
    "    - Spatial attention mechanism\n",
    "    - Multi-scale temporal convolutions\n",
    "    - Batch normalization adaptativo\n",
    "    - Regularização aprimorada\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=16, n_classes=2, n_samples=400, \n",
    "                 dropout_rate=0.25, kernel_length=64, F1=8, D=2, F2=16):\n",
    "        super(AdvancedEEGNet, self).__init__()\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Parâmetros da arquitetura\n",
    "        self.kernel_length = kernel_length\n",
    "        self.F1 = F1\n",
    "        self.D = D\n",
    "        self.F2 = F2\n",
    "        \n",
    "        # === BLOCO 1: Multi-scale Temporal Convolution ===\n",
    "        # Filtros de diferentes escalas temporais\n",
    "        self.temporal_conv1 = nn.Conv2d(1, F1//2, (1, kernel_length), padding=(0, kernel_length // 2), bias=False)\n",
    "        self.temporal_conv2 = nn.Conv2d(1, F1//2, (1, kernel_length//2), padding=(0, kernel_length // 4), bias=False)\n",
    "        self.temporal_bn = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        # === BLOCO 2: Spatial Attention + Depthwise Convolution ===\n",
    "        # Spatial attention\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(F1, F1//4, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(F1//4, F1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Depthwise convolution\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False),\n",
    "            nn.BatchNorm2d(F1 * D),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # === BLOCO 3: Enhanced Separable Convolution ===\n",
    "        self.separableConv = nn.Sequential(\n",
    "            # Depthwise\n",
    "            nn.Conv2d(F1 * D, F1 * D, (1, 16), padding=(0, 8), groups=F1 * D, bias=False),\n",
    "            # Pointwise\n",
    "            nn.Conv2d(F1 * D, F2, 1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # === BLOCO 4: Feature Enhancement ===\n",
    "        self.feature_enhancement = nn.Sequential(\n",
    "            nn.Conv2d(F2, F2*2, 1, bias=False),\n",
    "            nn.BatchNorm2d(F2*2),\n",
    "            nn.ELU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # === CLASSIFICADOR AVANÇADO ===\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(F2*2, F2),\n",
    "            nn.BatchNorm1d(F2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(F2, n_classes)\n",
    "        )\n",
    "        \n",
    "        # Inicialização dos pesos\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "        print(f\"✅ AdvancedEEGNet criado:\")\n",
    "        print(f\"   - Canais: {n_channels}\")\n",
    "        print(f\"   - Classes: {n_classes}\")\n",
    "        print(f\"   - Amostras: {n_samples}\")\n",
    "        print(f\"   - Parâmetros: {sum(p.numel() for p in self.parameters()):,}\")\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Inicialização dos pesos usando Xavier/He\"\"\"\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass com attention mechanism\n",
    "        Args:\n",
    "            x: tensor (batch_size, channels, samples) ou (batch_size, 1, channels, samples)\n",
    "        \"\"\"\n",
    "        # Garantir formato correto: (batch, 1, channels, samples)\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        # Bloco 1: Multi-scale temporal convolution\n",
    "        temp1 = self.temporal_conv1(x)\n",
    "        temp2 = self.temporal_conv2(x)\n",
    "        x = torch.cat([temp1, temp2], dim=1)  # Concatenar filtros multi-escala\n",
    "        x = self.temporal_bn(x)\n",
    "        \n",
    "        # Spatial attention\n",
    "        attention = self.spatial_attention(x)\n",
    "        x = x * attention  # Aplicar attention\n",
    "        \n",
    "        # Bloco 2: Depthwise convolution\n",
    "        x = self.depthwiseConv(x)\n",
    "        \n",
    "        # Bloco 3: Separable convolution\n",
    "        x = self.separableConv(x)\n",
    "        \n",
    "        # Bloco 4: Feature enhancement\n",
    "        x = self.feature_enhancement(x)\n",
    "        \n",
    "        # Classificador\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# === WRAPPER DE MODELO PERSONALIZADO ===\n",
    "class CustomEEGModel(nn.Module):\n",
    "    \"\"\"Wrapper para nosso modelo EEG personalizado\"\"\"\n",
    "    \n",
    "    def __init__(self, n_chans=16, n_outputs=2, n_times=400, sfreq=125.0, \n",
    "                 model_type='advanced', **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_chans = n_chans\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_times = n_times\n",
    "        self.sfreq = sfreq\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        # Escolher arquitetura\n",
    "        if model_type == 'advanced':\n",
    "            self.model = AdvancedEEGNet(\n",
    "                n_channels=n_chans,\n",
    "                n_classes=n_outputs,\n",
    "                n_samples=n_times,\n",
    "                dropout_rate=kwargs.get('dropout_rate', 0.25),\n",
    "                kernel_length=kwargs.get('kernel_length', 64),\n",
    "                F1=kwargs.get('F1', 8),\n",
    "                D=kwargs.get('D', 2),\n",
    "                F2=kwargs.get('F2', 16)\n",
    "            )\n",
    "            self.model_name = \"AdvancedEEGNet\"\n",
    "        else:  # basic\n",
    "            self.model = EEGNet(\n",
    "                n_channels=n_chans,\n",
    "                n_classes=n_outputs,\n",
    "                n_samples=n_times,\n",
    "                dropout_rate=kwargs.get('dropout_rate', 0.25),\n",
    "                kernel_length=kwargs.get('kernel_length', 64),\n",
    "                F1=kwargs.get('F1', 8),\n",
    "                D=kwargs.get('D', 2),\n",
    "                F2=kwargs.get('F2', 16)\n",
    "            )\n",
    "            self.model_name = \"EEGNet\"\n",
    "        \n",
    "        self.is_trained = False\n",
    "        \n",
    "        print(f\"✅ Modelo {self.model_name} inicializado\")\n",
    "        print(f\"📊 Parâmetros totais: {sum(p.numel() for p in self.parameters()):,}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def save_checkpoint(self, filepath, **kwargs):\n",
    "        \"\"\"Salvar checkpoint completo\"\"\"\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'model_type': self.model_name,\n",
    "            'constructor_args': {\n",
    "                'n_chans': self.n_chans,\n",
    "                'n_outputs': self.n_outputs,\n",
    "                'n_times': self.n_times,\n",
    "                'sfreq': self.sfreq,\n",
    "                'model_type': self.model_type\n",
    "            },\n",
    "            'is_trained': self.is_trained,\n",
    "            **kwargs\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        print(f\"✅ Modelo salvo: {filepath}\")\n",
    "\n",
    "# === TESTE DOS MODELOS ===\n",
    "print(\"🧪 Testando modelos...\")\n",
    "\n",
    "# Teste modelo básico\n",
    "basic_model = CustomEEGModel(model_type='basic')\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(2, 16, 400)\n",
    "    test_output = basic_model(test_input)\n",
    "    print(f\"✅ EEGNet Básico: {test_input.shape} -> {test_output.shape}\")\n",
    "\n",
    "# Teste modelo avançado\n",
    "advanced_model = CustomEEGModel(model_type='advanced')\n",
    "with torch.no_grad():\n",
    "    test_output_adv = advanced_model(test_input)\n",
    "    print(f\"✅ EEGNet Avançado: {test_input.shape} -> {test_output_adv.shape}\")\n",
    "\n",
    "# Comparar número de parâmetros\n",
    "basic_params = sum(p.numel() for p in basic_model.parameters())\n",
    "advanced_params = sum(p.numel() for p in advanced_model.parameters())\n",
    "\n",
    "print(f\"\\n📊 Comparação de Modelos:\")\n",
    "print(f\"   - EEGNet Básico: {basic_params:,} parâmetros\")\n",
    "print(f\"   - EEGNet Avançado: {advanced_params:,} parâmetros\")\n",
    "print(f\"   - Diferença: +{advanced_params - basic_params:,} parâmetros\")\n",
    "\n",
    "# Limpar memória\n",
    "del basic_model, advanced_model, test_input, test_output, test_output_adv\n",
    "\n",
    "print(\"\\n🎯 Modelos EEGNet personalizados prontos para treinamento!\")\n",
    "print(\"✅ Implementação 100% PyTorch sem dependências externas!\")\n",
    "\n",
    "# === EXECUÇÃO DO TREINAMENTO ===\n",
    "print(\"🚀 INICIANDO TREINAMENTO...\")\n",
    "\n",
    "try:\n",
    "    results, trained_model = train_eegnet_model(windows, labels, subject_ids, training_params)\n",
    "    \n",
    "    print(\"\\n🎉 TREINAMENTO CONCLUÍDO!\")\n",
    "    print(f\"📊 CV: {results['cv_mean']:.4f} ± {results['cv_std']:.4f}\")\n",
    "    print(f\"🎯 Teste: {results['test_accuracy']:.4f}\")\n",
    "    \n",
    "    # Salvar modelo\n",
    "    if results['model_state_dict'] is not None:\n",
    "        model_name = f\"custom_eegnet_{int(time.time())}\"\n",
    "        model_path = MODELS_PATH / f\"{model_name}.pt\"\n",
    "        \n",
    "        save_model = CustomEEGModel(**results['model_params'])\n",
    "        save_model.load_state_dict(results['model_state_dict'])\n",
    "        save_model.is_trained = True\n",
    "        \n",
    "        save_model.save_checkpoint(\n",
    "            model_path,\n",
    "            test_accuracy=results['test_accuracy'],\n",
    "            cv_mean=results['cv_mean'],\n",
    "            cv_std=results['cv_std'],\n",
    "            normalization_stats=results['normalization_stats']\n",
    "        )\n",
    "        \n",
    "        print(f\"💾 Modelo salvo: {model_path}\")\n",
    "        \n",
    "        # Salvar info para referência\n",
    "        with open(PROJECT_ROOT / \"modelo_atual.txt\", 'w') as f:\n",
    "            f.write(f\"Modelo: {model_path.name}\\n\")\n",
    "            f.write(f\"CV: {results['cv_mean']:.4f} ± {results['cv_std']:.4f}\\n\")\n",
    "            f.write(f\"Teste: {results['test_accuracy']:.4f}\\n\")\n",
    "            f.write(f\"Uso: python test_lsl_to_prediction_cycle.py\\n\")\n",
    "        \n",
    "        # Visualização simples\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar(['CV Mean', 'Test'], [results['cv_mean'], results['test_accuracy']], \n",
    "                color=['lightblue', 'lightgreen'])\n",
    "        plt.ylabel('Acurácia')\n",
    "        plt.title('Performance do Modelo')\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        plt.pie(counts, labels=['Mão Esquerda', 'Mão Direita'], autopct='%1.1f%%')\n",
    "        plt.title('Distribuição das Classes')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(RESULTS_PATH / f\"{model_name}_results.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"📊 Visualização salva: {model_name}_results.png\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Modelo não foi treinado com sucesso!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERRO: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n✅ PIPELINE CONCLUÍDO!\")\n",
    "print(\"🎯 Para usar no sistema LSL:\")\n",
    "print(\"   1. Copie o caminho do modelo salvo\")\n",
    "print(\"   2. Execute: python test_lsl_to_prediction_cycle.py\")\n",
    "print(\"   3. Modelo compatível com inferência em tempo real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9794978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️ Device: cpu\n",
      "✅ Modelo existente encontrado\n",
      "📊 Parâmetros do modelo: 16 canais, 400 amostras\n",
      "\n",
      "==================================================\n",
      "ARQUITETURA DO MODELO\n",
      "==================================================\n",
      "CustomEEGModel(\n",
      "  (model): AdvancedEEGNet(\n",
      "    (temporal_conv1): Conv2d(1, 4, kernel_size=(1, 64), stride=(1, 1), padding=(0, 32), bias=False)\n",
      "    (temporal_conv2): Conv2d(1, 4, kernel_size=(1, 32), stride=(1, 1), padding=(0, 16), bias=False)\n",
      "    (temporal_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (spatial_attention): Sequential(\n",
      "      (0): Conv2d(8, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(2, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "    (depthwiseConv): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(16, 1), stride=(1, 1), groups=8, bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
      "      (4): Dropout(p=0.25, inplace=False)\n",
      "    )\n",
      "    (separableConv): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), padding=(0, 8), groups=16, bias=False)\n",
      "      (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "      (5): Dropout(p=0.25, inplace=False)\n",
      "    )\n",
      "    (feature_enhancement): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (1): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Dropout(p=0.25, inplace=False)\n",
      "      (5): Linear(in_features=16, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "📈 ESTATÍSTICAS DO MODELO:\n",
      "   Total de parâmetros: 2,444\n",
      "   Parâmetros treináveis: 2,444\n",
      "   Parâmetros não-treináveis: 0\n",
      "   Status: ❌ NÃO TREINADO\n",
      "\n",
      "==================================================\n",
      "SUMÁRIO DETALHADO\n",
      "==================================================\n",
      "⚠️ Para obter um sumário detalhado, instale uma das bibliotecas:\n",
      "   pip install torchinfo   # (recomendado)\n",
      "   pip install torchsummary\n",
      "\n",
      "📋 SUMÁRIO MANUAL:\n",
      "   model.temporal_conv1: Conv2d - 256 parâmetros\n",
      "   model.temporal_conv2: Conv2d - 128 parâmetros\n",
      "   model.temporal_bn: BatchNorm2d - 16 parâmetros\n",
      "   model.spatial_attention.0: Conv2d - 18 parâmetros\n",
      "   model.spatial_attention.2: Conv2d - 24 parâmetros\n",
      "   model.depthwiseConv.0: Conv2d - 256 parâmetros\n",
      "   model.depthwiseConv.1: BatchNorm2d - 32 parâmetros\n",
      "   model.separableConv.0: Conv2d - 256 parâmetros\n",
      "   model.separableConv.1: Conv2d - 256 parâmetros\n",
      "   model.separableConv.2: BatchNorm2d - 32 parâmetros\n",
      "   model.feature_enhancement.0: Conv2d - 512 parâmetros\n",
      "   model.feature_enhancement.1: BatchNorm2d - 64 parâmetros\n",
      "   model.classifier.1: Linear - 528 parâmetros\n",
      "   model.classifier.2: BatchNorm1d - 32 parâmetros\n",
      "   model.classifier.5: Linear - 34 parâmetros\n",
      "\n",
      "==================================================\n",
      "TESTE FORWARD PASS\n",
      "==================================================\n",
      "✅ Teste bem-sucedido!\n",
      "   Input: torch.Size([2, 16, 400])\n",
      "   Output: torch.Size([2, 2])\n",
      "   Probabilidades (exemplo): [0.50132763 0.49867237]\n",
      "\n",
      "==================================================\n",
      "SUMÁRIO COMPLETO FINALIZADO\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────── Célula: Sumário do Modelo ────────────────────\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 0) Configurar device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🖥️ Device: {device}\")\n",
    "\n",
    "# 1) Verificar se modelo existe ou carregar/criar um\n",
    "if 'model' not in locals() and 'model' not in globals():\n",
    "    print(\"⚠️ Modelo não encontrado. Criando opções...\")\n",
    "    \n",
    "    # Opção 1: Tentar carregar modelo salvo mais recente\n",
    "    MODELS_PATH = Path.cwd() / \"models\"\n",
    "    if MODELS_PATH.exists():\n",
    "        model_files = list(MODELS_PATH.glob(\"*.pt\"))\n",
    "        if model_files:\n",
    "            latest_model = max(model_files, key=os.path.getctime)\n",
    "            print(f\"📁 Modelo encontrado: {latest_model.name}\")\n",
    "            \n",
    "            try:\n",
    "                checkpoint = torch.load(latest_model, map_location=device)\n",
    "                \n",
    "                # Criar modelo baseado nos parâmetros salvos\n",
    "                if 'constructor_args' in checkpoint:\n",
    "                    args = checkpoint['constructor_args']\n",
    "                    model = CustomEEGModel(**args)\n",
    "                    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                    model.to(device)\n",
    "                    print(f\"✅ Modelo carregado: {latest_model.name}\")\n",
    "                else:\n",
    "                    raise ValueError(\"Checkpoint inválido\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erro ao carregar modelo: {e}\")\n",
    "                model = None\n",
    "        else:\n",
    "            print(\"📁 Nenhum modelo salvo encontrado\")\n",
    "            model = None\n",
    "    else:\n",
    "        print(\"📁 Diretório de modelos não encontrado\")\n",
    "        model = None\n",
    "    \n",
    "    # Opção 2: Criar modelo para demonstração se não conseguiu carregar\n",
    "    if model is None:\n",
    "        print(\"🛠️ Criando modelo de demonstração...\")\n",
    "        model = CustomEEGModel(\n",
    "            n_chans=16,\n",
    "            n_outputs=2,\n",
    "            n_times=400,\n",
    "            sfreq=125.0,\n",
    "            model_type='advanced'\n",
    "        )\n",
    "        model.to(device)\n",
    "        print(\"✅ Modelo de demonstração criado\")\n",
    "\n",
    "else:\n",
    "    # Modelo já existe, apenas mover para device\n",
    "    model.to(device)\n",
    "    print(\"✅ Modelo existente encontrado\")\n",
    "\n",
    "# 2) Capturar parâmetros de forma genérica\n",
    "try:\n",
    "    n_channels = model.n_chans      # para CustomEEGModel\n",
    "    n_samples  = model.n_times\n",
    "    print(f\"📊 Parâmetros do modelo: {n_channels} canais, {n_samples} amostras\")\n",
    "except AttributeError:\n",
    "    try:\n",
    "        n_channels = model.n_channels\n",
    "        n_samples  = model.n_samples\n",
    "        print(f\"📊 Parâmetros do modelo: {n_channels} canais, {n_samples} amostras\")\n",
    "    except AttributeError:\n",
    "        n_channels = 16\n",
    "        n_samples  = 400\n",
    "        print(f\"📊 Usando parâmetros padrão: {n_channels} canais, {n_samples} amostras\")\n",
    "\n",
    "# 3) Imprimir arquitetura do modelo\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ARQUITETURA DO MODELO\")\n",
    "print(\"=\"*50)\n",
    "print(model)\n",
    "\n",
    "# 4) Contagem de parâmetros\n",
    "total_params     = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\n📈 ESTATÍSTICAS DO MODELO:\")\n",
    "print(f\"   Total de parâmetros: {total_params:,}\")\n",
    "print(f\"   Parâmetros treináveis: {trainable_params:,}\")\n",
    "print(f\"   Parâmetros não-treináveis: {total_params - trainable_params:,}\")\n",
    "\n",
    "# 5) Verificar se modelo foi treinado\n",
    "if hasattr(model, 'is_trained'):\n",
    "    status = \"✅ TREINADO\" if model.is_trained else \"❌ NÃO TREINADO\"\n",
    "    print(f\"   Status: {status}\")\n",
    "\n",
    "# 6) Sumário detalhado usando torchinfo ou torchsummary\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"SUMÁRIO DETALHADO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary as info_summary\n",
    "    print(\"Usando torchinfo...\")\n",
    "    info_summary(model, input_size=(1, n_channels, n_samples), device=device)\n",
    "except ImportError:\n",
    "    try:\n",
    "        from torchsummary import summary as ts_summary\n",
    "        print(\"Usando torchsummary...\")\n",
    "        ts_summary(model, input_size=(n_channels, n_samples))\n",
    "    except ImportError:\n",
    "        print(\"⚠️ Para obter um sumário detalhado, instale uma das bibliotecas:\")\n",
    "        print(\"   pip install torchinfo   # (recomendado)\")\n",
    "        print(\"   pip install torchsummary\")\n",
    "        \n",
    "        # Sumário manual básico\n",
    "        print(\"\\n📋 SUMÁRIO MANUAL:\")\n",
    "        for name, module in model.named_modules():\n",
    "            if len(list(module.children())) == 0:  # Apenas camadas folha\n",
    "                params = sum(p.numel() for p in module.parameters())\n",
    "                if params > 0:\n",
    "                    print(f\"   {name}: {module.__class__.__name__} - {params:,} parâmetros\")\n",
    "\n",
    "# 7) Teste forward pass\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"TESTE FORWARD PASS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_input = torch.randn(2, n_channels, n_samples).to(device)\n",
    "        test_output = model(test_input)\n",
    "        print(f\"✅ Teste bem-sucedido!\")\n",
    "        print(f\"   Input: {test_input.shape}\")\n",
    "        print(f\"   Output: {test_output.shape}\")\n",
    "        print(f\"   Probabilidades (exemplo): {torch.softmax(test_output[0], dim=0).cpu().numpy()}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro no teste: {e}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"SUMÁRIO COMPLETO FINALIZADO\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
