{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725a5162",
   "metadata": {
    "id": "725a5162"
   },
   "source": [
    "# BCI Training Pipeline - EEGNet Personalizada\n",
    "\n",
    "Pipeline de treinamento para BCI usando CNN personalizada baseada no EEGNet:\n",
    "\n",
    "1. **EEGNet Personalizado**: ImplementaÃ§Ã£o prÃ³pria PyTorch\n",
    "2. **Pipeline de Treinamento**: Cross-validation e early stopping  \n",
    "3. **NormalizaÃ§Ã£o Robusta**: Tratamento de outliers\n",
    "4. **Dados OpenBCI**: Suporte para CSV da OpenBCI GUI\n",
    "5. **InferÃªncia em Tempo Real**: CompatÃ­vel com sistema LSL\n",
    "\n",
    "## ðŸŽ¯ Objetivo: CNN otimizada para BCI em tempo real (sem braindecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "y9I7ySM2Ag5G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9I7ySM2Ag5G",
    "outputId": "7517a75c-8288-4748-e176-2c42554b1e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸ Device: cpu\n",
      "ðŸ PyTorch version: 2.7.1+cpu\n",
      "ðŸ“‚ Projeto: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\n",
      "ðŸ“Š Dados: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\EndUser\\eeg_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0\n",
      "ðŸ¤– Modelos: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\n",
      "âœ… ConfiguraÃ§Ãµes bÃ¡sicas carregadas!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS E CONFIGURAÃ‡Ã•ES BÃSICAS ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from collections import deque\n",
    "from scipy import signal\n",
    "import mne\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Verificar device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ–¥ï¸ Device: {device}\")\n",
    "print(f\"ðŸ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Configurar paths\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_PATH = PROJECT_ROOT / \"EndUser\" / \"eeg_data\" / \"MNE-eegbci-data\" / \"files\" / \"eegmmidb\" / \"1.0.0\"\n",
    "MODELS_PATH = PROJECT_ROOT / \"models\"\n",
    "RESULTS_PATH = PROJECT_ROOT / \"results\"\n",
    "\n",
    "# Criar diretÃ³rios se nÃ£o existirem\n",
    "MODELS_PATH.mkdir(exist_ok=True)\n",
    "RESULTS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"ðŸ“‚ Projeto: {PROJECT_ROOT}\")\n",
    "print(f\"ðŸ“Š Dados: {DATA_PATH}\")\n",
    "print(f\"ðŸ¤– Modelos: {MODELS_PATH}\")\n",
    "print(\"âœ… ConfiguraÃ§Ãµes bÃ¡sicas carregadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021874a4",
   "metadata": {
    "id": "021874a4"
   },
   "source": [
    "## 1. Setup Inicial no Google Colab\n",
    "\n",
    "Vamos instalar as dependÃªncias e configurar o ambiente adequadamente.\n",
    "\n",
    "# 1. Modelo EEGNet Personalizado\n",
    "\n",
    "ImplementaÃ§Ã£o prÃ³pria do EEGNet usando apenas PyTorch:\n",
    "\n",
    "- **Depthwise Separable Convolutions**: Reduz parÃ¢metros\n",
    "- **Temporal e Spatial Filtering**: Especializado para EEG  \n",
    "- **Dropout e Batch Normalization**: RegularizaÃ§Ã£o\n",
    "- **Arquitetura FlexÃ­vel**: AdaptÃ¡vel para diferentes configuraÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecdd2a3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ecdd2a3e",
    "outputId": "33f9fb43-5694-4494-930c-955e103ec0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Instalando dependÃªncias necessÃ¡rias...\n",
      "Requirement already satisfied: mne in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: torch in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.10.3)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (2.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (25.0)\n",
      "Requirement already satisfied: pooch>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (2.32.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.6.15)\n",
      "Requirement already satisfied: mne in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.0)\n",
      "Requirement already satisfied: torch in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (0.4)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (3.10.3)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (2.3.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (25.0)\n",
      "Requirement already satisfied: pooch>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.8.2)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mne) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.6->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pooch>=1.5->mne) (2.32.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->mne) (3.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.6.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.16.0)\n",
      "Requirement already satisfied: jupyter in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scipy) (2.3.1)\n",
      "Requirement already satisfied: notebook in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (7.4.3)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (8.1.7)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter) (4.4.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (9.3.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipykernel->jupyter) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel->jupyter) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets->jupyter) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets->jupyter) (3.0.15)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-console->jupyter) (3.0.51)\n",
      "Requirement already satisfied: pygments in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-console->jupyter) (2.19.2)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (0.28.1)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (2.16.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (0.2.4)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab->jupyter) (80.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter) (1.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (310)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.0.15)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (4.24.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.21.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (4.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (21.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (0.25.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (0.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->jupyter) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\chari\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter) (0.2.3)\n",
      "Requirement already satisfied: fqdn in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\chari\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (2.9.0.20250516)\n",
      "âœ… DependÃªncias instaladas!\n",
      "ðŸ’» Executando localmente\n",
      "âœ… EEGNet criado: 1,746 parÃ¢metros\n",
      "âœ… Teste: torch.Size([2, 16, 400]) -> torch.Size([2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# === INSTALAÃ‡ÃƒO DE DEPENDÃŠNCIAS ===\n",
    "print(\"ðŸ”§ Instalando dependÃªncias necessÃ¡rias...\")\n",
    "\n",
    "# Instalar apenas dependÃªncias cientÃ­ficas essenciais (sem braindecode)\n",
    "!pip install mne torch torchvision torchaudio\n",
    "!pip install scikit-learn pandas numpy matplotlib seaborn\n",
    "!pip install scipy jupyter\n",
    "\n",
    "print(\"âœ… DependÃªncias instaladas!\")\n",
    "\n",
    "# Verificar se estÃ¡ no Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ðŸ“± Executando no Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ðŸ’» Executando localmente\")\n",
    "\n",
    "# === MODELO EEGNET PERSONALIZADO ===\n",
    "class EEGNet(nn.Module):\n",
    "    \"\"\"ImplementaÃ§Ã£o compacta do EEGNet para BCI\"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=16, n_classes=2, n_samples=400, \n",
    "                 dropout_rate=0.25, kernel_length=64, F1=8, D=2, F2=16):\n",
    "        super(EEGNet, self).__init__()\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "        # Bloco 1: Temporal Convolution\n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, F1, (1, kernel_length), padding=(0, kernel_length // 2), bias=False),\n",
    "            nn.BatchNorm2d(F1)\n",
    "        )\n",
    "        \n",
    "        # Bloco 2: Depthwise Convolution (Spatial filtering)\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False),\n",
    "            nn.BatchNorm2d(F1 * D),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Bloco 3: Separable Convolution\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(F1 * D, F1 * D, (1, 16), padding=(0, 8), groups=F1 * D, bias=False),\n",
    "            nn.Conv2d(F1 * D, F2, 1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # Classificador\n",
    "        self.feature_size = self._get_conv_output_size()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.feature_size, n_classes)\n",
    "        )\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        print(f\"âœ… EEGNet criado: {sum(p.numel() for p in self.parameters()):,} parÃ¢metros\")\n",
    "    \n",
    "    def _get_conv_output_size(self):\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, self.n_channels, self.n_samples)\n",
    "            x = self.firstconv(dummy_input)\n",
    "            x = self.depthwiseConv(x)\n",
    "            x = self.separableConv(x)\n",
    "            return x.numel()\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)  # (batch, channels, samples) -> (batch, 1, channels, samples)\n",
    "        \n",
    "        x = self.firstconv(x)\n",
    "        x = self.depthwiseConv(x)\n",
    "        x = self.separableConv(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# === WRAPPER PARA COMPATIBILIDADE ===\n",
    "class CustomEEGModel(nn.Module):\n",
    "    def __init__(self, n_chans=16, n_outputs=2, n_times=400, sfreq=125.0, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_chans = n_chans\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_times = n_times\n",
    "        self.sfreq = sfreq\n",
    "        \n",
    "        self.model = EEGNet(n_channels=n_chans, n_classes=n_outputs, n_samples=n_times)\n",
    "        self.model_type = \"CustomEEGNet\"\n",
    "        self.is_trained = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def save_checkpoint(self, filepath, **kwargs):\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'model_type': self.model_type,\n",
    "            'constructor_args': {\n",
    "                'n_chans': self.n_chans,\n",
    "                'n_outputs': self.n_outputs,\n",
    "                'n_times': self.n_times,\n",
    "                'sfreq': self.sfreq\n",
    "            },\n",
    "            'is_trained': self.is_trained,\n",
    "            **kwargs\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        print(f\"âœ… Modelo salvo: {filepath}\")\n",
    "\n",
    "# Teste do modelo\n",
    "test_model = CustomEEGModel()\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(2, 16, 400)\n",
    "    test_output = test_model(test_input)\n",
    "    print(f\"âœ… Teste: {test_input.shape} -> {test_output.shape}\")\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e4587fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e4587fa",
    "outputId": "e22d80a4-c3c3-4657-f57b-6a3b4eebd828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports bÃ¡sicos carregados!\n",
      "ðŸ“¥ Gerando dados sintÃ©ticos para demonstraÃ§Ã£o...\n",
      "âœ… Dados carregados: (200, 16, 400)\n",
      "ðŸŽ¯ Classes: {np.int32(0): np.int64(100), np.int32(1): np.int64(100)}\n",
      "ðŸ‘¥ Sujeitos: 5\n",
      "âœ… Classes e normalizaÃ§Ã£o implementadas!\n"
     ]
    }
   ],
   "source": [
    "# === IMPLEMENTAÃ‡ÃƒO INLINE DAS CLASSES BASE ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from typing import Optional, List, Tuple, Dict, Union\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "import mne\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… Imports bÃ¡sicos carregados!\")\n",
    "\n",
    "# === CARREGAMENTO DE DADOS E NORMALIZAÃ‡ÃƒO ===\n",
    "class RobustEEGNormalizer:\n",
    "    \"\"\"Normalizador robusto para dados EEG\"\"\"\n",
    "    \n",
    "    def __init__(self, method='robust_zscore', outlier_threshold=3.0):\n",
    "        self.method = method\n",
    "        self.outlier_threshold = outlier_threshold\n",
    "        self.stats = {}\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # Garantir formato 3D (trials, channels, time)\n",
    "        if len(X.shape) == 2:\n",
    "            X = X.reshape(X.shape[0], 16, -1)\n",
    "        \n",
    "        # Tratar outliers usando IQR\n",
    "        Q1 = np.percentile(X, 25, axis=(0, 2), keepdims=True)\n",
    "        Q3 = np.percentile(X, 75, axis=(0, 2), keepdims=True)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - self.outlier_threshold * IQR\n",
    "        upper = Q3 + self.outlier_threshold * IQR\n",
    "        X = np.clip(X, lower, upper)\n",
    "        \n",
    "        # Calcular estatÃ­sticas por canal\n",
    "        self.stats['median'] = np.median(X, axis=(0, 2), keepdims=True)\n",
    "        self.stats['iqr'] = IQR + 1e-8\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Deve ajustar antes de transformar\")\n",
    "        \n",
    "        original_shape = X.shape\n",
    "        if len(X.shape) == 2:\n",
    "            X = X.reshape(X.shape[0], 16, -1)\n",
    "        \n",
    "        X_norm = (X - self.stats['median']) / self.stats['iqr']\n",
    "        \n",
    "        if len(original_shape) == 2:\n",
    "            X_norm = X_norm.reshape(original_shape)\n",
    "        return X_norm\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return self.stats.copy()\n",
    "\n",
    "# === DATASET PYTORCH ===\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, windows, labels, augment=False):\n",
    "        self.windows = torch.from_numpy(windows).float()\n",
    "        self.labels = torch.from_numpy(labels).long()\n",
    "        self.augment = augment\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        window = self.windows[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.augment and torch.rand(1) < 0.3:\n",
    "            # Adicionar ruÃ­do leve para augmentaÃ§Ã£o\n",
    "            noise = torch.randn_like(window) * 0.01\n",
    "            window = window + noise\n",
    "        \n",
    "        return window, label\n",
    "\n",
    "# === CARREGAR DADOS ===\n",
    "def load_openbci_csv(file_path, sfreq=125):\n",
    "    \"\"\"Carrega arquivo CSV da OpenBCI\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, comment='%')\n",
    "        eeg_cols = [col for col in df.columns if 'EXG Channel' in col]\n",
    "        \n",
    "        if len(eeg_cols) == 0:\n",
    "            return None\n",
    "        \n",
    "        data = df[eeg_cols].T.to_numpy() * 1e-6  # ÂµV -> V\n",
    "        info = mne.create_info(ch_names=eeg_cols, sfreq=sfreq, ch_types='eeg')\n",
    "        raw = mne.io.RawArray(data, info, verbose=False)\n",
    "        \n",
    "        # Adicionar anotaÃ§Ãµes T1/T2\n",
    "        if 'Annotations' in df.columns:\n",
    "            onsets = df.index.to_numpy() / sfreq\n",
    "            for onset, annot in zip(onsets, df['Annotations'].astype(str)):\n",
    "                if annot.startswith('T'):\n",
    "                    raw.annotations.append(onset, 0, annot)\n",
    "        \n",
    "        return raw\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro ao carregar {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Gerar dados sintÃ©ticos para demonstraÃ§Ã£o (substitua pela funÃ§Ã£o de carregamento real)\n",
    "print(\"ðŸ“¥ Gerando dados sintÃ©ticos para demonstraÃ§Ã£o...\")\n",
    "n_trials, n_channels, n_samples = 200, 16, 400\n",
    "np.random.seed(42)\n",
    "\n",
    "windows = np.random.randn(n_trials, n_channels, n_samples) * 0.1\n",
    "labels = np.random.randint(0, 2, n_trials)\n",
    "subject_ids = np.random.randint(1, 6, n_trials)\n",
    "\n",
    "# Adicionar padrÃµes especÃ­ficos por classe\n",
    "for i in range(n_trials):\n",
    "    if labels[i] == 0:  # MÃ£o esquerda\n",
    "        windows[i, :8, 100:150] += 0.05 * np.sin(np.linspace(0, 4*np.pi, 50))\n",
    "    else:  # MÃ£o direita\n",
    "        windows[i, 8:, 150:200] += 0.05 * np.sin(np.linspace(0, 4*np.pi, 50))\n",
    "\n",
    "print(f\"âœ… Dados carregados: {windows.shape}\")\n",
    "print(f\"ðŸŽ¯ Classes: {dict(zip(*np.unique(labels, return_counts=True)))}\")\n",
    "print(f\"ðŸ‘¥ Sujeitos: {len(np.unique(subject_ids))}\")\n",
    "\n",
    "print(\"âœ… Classes e normalizaÃ§Ã£o implementadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a7fe101",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a7fe101",
    "outputId": "04ea0cdc-4a63-4d5b-8552-76dae598e233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… UniversalEEGNormalizer implementado!\n",
      "âš™ï¸ ParÃ¢metros: {'n_folds': 5, 'n_epochs': 30, 'batch_size': 16, 'learning_rate': 0.001, 'patience': 10}\n",
      "ðŸŽ¯ Pronto para treinamento!\n"
     ]
    }
   ],
   "source": [
    "# === UNIVERSAL EEG NORMALIZER ===\n",
    "class UniversalEEGNormalizer:\n",
    "    \"\"\"Normalizador universal para dados EEG\"\"\"\n",
    "\n",
    "    def __init__(self, method: str = 'zscore', mode: str = 'training'):\n",
    "        self.method = method\n",
    "        self.mode = mode\n",
    "        self.global_stats = {}\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def _ensure_3d(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Garantir que dados estejam em 3D (n_samples, n_channels, n_timepoints)\"\"\"\n",
    "        if len(data.shape) == 2:\n",
    "            n_samples, n_features = data.shape\n",
    "            if n_features % 16 == 0:  # Assumir 16 canais\n",
    "                n_channels = 16\n",
    "                n_timepoints = n_features // n_channels\n",
    "                data = data.reshape(n_samples, n_channels, n_timepoints)\n",
    "            else:\n",
    "                data = data[:, np.newaxis, :]\n",
    "        elif len(data.shape) == 1:\n",
    "            data = data[np.newaxis, np.newaxis, :]\n",
    "        return data\n",
    "\n",
    "    def fit(self, data: np.ndarray):\n",
    "        \"\"\"Ajustar normalizador aos dados\"\"\"\n",
    "        data_3d = self._ensure_3d(data)\n",
    "\n",
    "        if self.method == 'zscore':\n",
    "            self.global_stats['mean'] = np.mean(data_3d, axis=(0, 2), keepdims=True)\n",
    "            self.global_stats['std'] = np.std(data_3d, axis=(0, 2), keepdims=True)\n",
    "            self.global_stats['std'] = np.where(self.global_stats['std'] == 0, 1.0, self.global_stats['std'])\n",
    "\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transformar dados\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Normalizador deve ser ajustado antes da transformaÃ§Ã£o\")\n",
    "\n",
    "        original_shape = data.shape\n",
    "        data_3d = self._ensure_3d(data)\n",
    "\n",
    "        if self.method == 'zscore':\n",
    "            normalized = (data_3d - self.global_stats['mean']) / self.global_stats['std']\n",
    "\n",
    "        # Restaurar forma original\n",
    "        if len(original_shape) == 2:\n",
    "            return normalized.reshape(original_shape[0], -1)\n",
    "        elif len(original_shape) == 1:\n",
    "            return normalized.flatten()\n",
    "        return normalized\n",
    "\n",
    "    def fit_transform(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Ajustar e transformar em um passo\"\"\"\n",
    "        return self.fit(data).transform(data)\n",
    "\n",
    "print(\"âœ… UniversalEEGNormalizer implementado!\")\n",
    "\n",
    "# === PIPELINE DE TREINAMENTO SIMPLIFICADO ===\n",
    "def train_eegnet_model(windows, labels, subject_ids, params):\n",
    "    \"\"\"Pipeline completo de treinamento do modelo EEGNet\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ Iniciando treinamento...\")\n",
    "    \n",
    "    # NormalizaÃ§Ã£o\n",
    "    normalizer = RobustEEGNormalizer()\n",
    "    windows_norm = normalizer.fit_transform(windows)\n",
    "    print(f\"âœ… NormalizaÃ§Ã£o: mÃ©dia={np.mean(windows_norm):.4f}, std={np.std(windows_norm):.4f}\")\n",
    "    \n",
    "    # Split treino/teste\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        windows_norm, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Cross-validation\n",
    "    kfold = KFold(n_splits=params.get('n_folds', 5), shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    best_model_state = None\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train_val), 1):\n",
    "        print(f\"\\nðŸ“ Fold {fold}\")\n",
    "        \n",
    "        # Dados do fold\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "        \n",
    "        # DataLoaders\n",
    "        train_dataset = EEGDataset(X_train, y_train, augment=True)\n",
    "        val_dataset = EEGDataset(X_val, y_val, augment=False)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=params.get('batch_size', 16), shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=params.get('batch_size', 16), shuffle=False)\n",
    "        \n",
    "        # Modelo\n",
    "        model = CustomEEGModel(\n",
    "            n_chans=windows.shape[1],\n",
    "            n_outputs=len(np.unique(labels)),\n",
    "            n_times=windows.shape[2]\n",
    "        ).to(device)\n",
    "        \n",
    "        # Otimizador\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=params.get('learning_rate', 1e-3))\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Treinamento\n",
    "        best_fold_val_acc = 0.0\n",
    "        patience_count = 0\n",
    "        \n",
    "        for epoch in range(params.get('n_epochs', 30)):\n",
    "            # Treino\n",
    "            model.train()\n",
    "            train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "            \n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += batch_y.size(0)\n",
    "                train_correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            # ValidaÃ§Ã£o\n",
    "            model.eval()\n",
    "            val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                    outputs = model(batch_x)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    \n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    val_total += batch_y.size(0)\n",
    "                    val_correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            train_acc = train_correct / train_total\n",
    "            val_acc = val_correct / val_total\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_acc > best_fold_val_acc:\n",
    "                best_fold_val_acc = val_acc\n",
    "                patience_count = 0\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "            else:\n",
    "                patience_count += 1\n",
    "                if patience_count >= params.get('patience', 10):\n",
    "                    break\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"   Ã‰poca {epoch+1}: Train {train_acc:.3f} | Val {val_acc:.3f}\")\n",
    "        \n",
    "        fold_accuracies.append(best_fold_val_acc)\n",
    "        print(f\"   âœ… Fold {fold} concluÃ­do - Val Acc: {best_fold_val_acc:.4f}\")\n",
    "    \n",
    "    # EstatÃ­sticas CV\n",
    "    cv_mean = np.mean(fold_accuracies)\n",
    "    cv_std = np.std(fold_accuracies)\n",
    "    print(f\"\\nðŸ“Š CV: {cv_mean:.4f} Â± {cv_std:.4f}\")\n",
    "    \n",
    "    # Teste final\n",
    "    if best_model_state is not None:\n",
    "        final_model = CustomEEGModel(\n",
    "            n_chans=windows.shape[1],\n",
    "            n_outputs=len(np.unique(labels)),\n",
    "            n_times=windows.shape[2]\n",
    "        ).to(device)\n",
    "        final_model.load_state_dict(best_model_state)\n",
    "        final_model.eval()\n",
    "        \n",
    "        test_dataset = EEGDataset(X_test, y_test)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        test_correct = test_total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = final_model(batch_x)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                test_total += batch_y.size(0)\n",
    "                test_correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        test_acc = test_correct / test_total\n",
    "        print(f\"ðŸŽ¯ Teste final: {test_acc:.4f}\")\n",
    "    else:\n",
    "        test_acc = 0.0\n",
    "        final_model = None\n",
    "    \n",
    "    results = {\n",
    "        'model_state_dict': best_model_state,\n",
    "        'cv_mean': cv_mean,\n",
    "        'cv_std': cv_std,\n",
    "        'test_accuracy': test_acc,\n",
    "        'normalization_stats': normalizer.get_stats(),\n",
    "        'model_params': {\n",
    "            'n_chans': windows.shape[1],\n",
    "            'n_outputs': len(np.unique(labels)),\n",
    "            'n_times': windows.shape[2],\n",
    "            'sfreq': 125.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results, final_model\n",
    "\n",
    "# === CONFIGURAÃ‡ÃƒO E EXECUÃ‡ÃƒO ===\n",
    "training_params = {\n",
    "    'n_folds': 5,\n",
    "    'n_epochs': 30,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 1e-3,\n",
    "    'patience': 10\n",
    "}\n",
    "\n",
    "print(\"âš™ï¸ ParÃ¢metros:\", training_params)\n",
    "print(\"ðŸŽ¯ Pronto para treinamento!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bec4ebbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bec4ebbc",
    "outputId": "37963b05-791a-4db7-e486-c99863101af0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testando modelos...\n",
      "âœ… EEGNet criado: 1,746 parÃ¢metros\n",
      "âœ… Modelo EEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 1,746\n",
      "âœ… EEGNet BÃ¡sico: torch.Size([2, 16, 400]) -> torch.Size([2, 2])\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "âœ… EEGNet AvanÃ§ado: torch.Size([2, 16, 400]) -> torch.Size([2, 2])\n",
      "\n",
      "ðŸ“Š ComparaÃ§Ã£o de Modelos:\n",
      "   - EEGNet BÃ¡sico: 1,746 parÃ¢metros\n",
      "   - EEGNet AvanÃ§ado: 2,444 parÃ¢metros\n",
      "   - DiferenÃ§a: +698 parÃ¢metros\n",
      "\n",
      "ðŸŽ¯ Modelos EEGNet personalizados prontos para treinamento!\n",
      "âœ… ImplementaÃ§Ã£o 100% PyTorch sem dependÃªncias externas!\n",
      "ðŸš€ INICIANDO TREINAMENTO...\n",
      "ðŸš€ Iniciando treinamento...\n",
      "âœ… NormalizaÃ§Ã£o: mÃ©dia=-0.0001, std=0.7410\n",
      "\n",
      "ðŸ“ Fold 1\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   Ã‰poca 10: Train 0.695 | Val 0.781\n",
      "   Ã‰poca 10: Train 0.695 | Val 0.781\n",
      "   Ã‰poca 20: Train 0.922 | Val 0.844\n",
      "   Ã‰poca 20: Train 0.922 | Val 0.844\n",
      "   âœ… Fold 1 concluÃ­do - Val Acc: 0.8750\n",
      "\n",
      "ðŸ“ Fold 2\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   âœ… Fold 1 concluÃ­do - Val Acc: 0.8750\n",
      "\n",
      "ðŸ“ Fold 2\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   Ã‰poca 10: Train 0.695 | Val 0.719\n",
      "   Ã‰poca 10: Train 0.695 | Val 0.719\n",
      "   Ã‰poca 20: Train 0.875 | Val 0.844\n",
      "   Ã‰poca 20: Train 0.875 | Val 0.844\n",
      "   âœ… Fold 2 concluÃ­do - Val Acc: 0.9062\n",
      "\n",
      "ðŸ“ Fold 3\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   âœ… Fold 2 concluÃ­do - Val Acc: 0.9062\n",
      "\n",
      "ðŸ“ Fold 3\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   Ã‰poca 10: Train 0.641 | Val 0.562\n",
      "   Ã‰poca 10: Train 0.641 | Val 0.562\n",
      "   âœ… Fold 3 concluÃ­do - Val Acc: 0.6562\n",
      "\n",
      "ðŸ“ Fold 4\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   âœ… Fold 3 concluÃ­do - Val Acc: 0.6562\n",
      "\n",
      "ðŸ“ Fold 4\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   Ã‰poca 10: Train 0.578 | Val 0.688\n",
      "   Ã‰poca 10: Train 0.578 | Val 0.688\n",
      "   Ã‰poca 20: Train 0.812 | Val 0.844\n",
      "   Ã‰poca 20: Train 0.812 | Val 0.844\n",
      "   Ã‰poca 30: Train 0.961 | Val 0.969\n",
      "   âœ… Fold 4 concluÃ­do - Val Acc: 0.9688\n",
      "\n",
      "ðŸ“ Fold 5\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   Ã‰poca 30: Train 0.961 | Val 0.969\n",
      "   âœ… Fold 4 concluÃ­do - Val Acc: 0.9688\n",
      "\n",
      "ðŸ“ Fold 5\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   Ã‰poca 10: Train 0.688 | Val 0.500\n",
      "   âœ… Fold 5 concluÃ­do - Val Acc: 0.7188\n",
      "\n",
      "ðŸ“Š CV: 0.8250 Â± 0.1179\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "   Ã‰poca 10: Train 0.688 | Val 0.500\n",
      "   âœ… Fold 5 concluÃ­do - Val Acc: 0.7188\n",
      "\n",
      "ðŸ“Š CV: 0.8250 Â± 0.1179\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "ðŸŽ¯ Teste final: 0.9750\n",
      "\n",
      "ðŸŽ‰ TREINAMENTO CONCLUÃDO!\n",
      "ðŸ“Š CV: 0.8250 Â± 0.1179\n",
      "ðŸŽ¯ Teste: 0.9750\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "âœ… Modelo salvo: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\\custom_eegnet_1751259706.pt\n",
      "ðŸ’¾ Modelo salvo: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\\custom_eegnet_1751259706.pt\n",
      "ðŸŽ¯ Teste final: 0.9750\n",
      "\n",
      "ðŸŽ‰ TREINAMENTO CONCLUÃDO!\n",
      "ðŸ“Š CV: 0.8250 Â± 0.1179\n",
      "ðŸŽ¯ Teste: 0.9750\n",
      "âœ… AdvancedEEGNet criado:\n",
      "   - Canais: 16\n",
      "   - Classes: 2\n",
      "   - Amostras: 400\n",
      "   - ParÃ¢metros: 2,444\n",
      "âœ… Modelo AdvancedEEGNet inicializado\n",
      "ðŸ“Š ParÃ¢metros totais: 2,444\n",
      "âœ… Modelo salvo: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\\custom_eegnet_1751259706.pt\n",
      "ðŸ’¾ Modelo salvo: c:\\Users\\Chari\\OneDrive\\Documentos\\GitHub\\projetoBCI-1\\models\\custom_eegnet_1751259706.pt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š VisualizaÃ§Ã£o salva: custom_eegnet_1751259706_results.png\n",
      "\n",
      "âœ… PIPELINE CONCLUÃDO!\n",
      "ðŸŽ¯ Para usar no sistema LSL:\n",
      "   1. Copie o caminho do modelo salvo\n",
      "   2. Execute: python test_lsl_to_prediction_cycle.py\n",
      "   3. Modelo compatÃ­vel com inferÃªncia em tempo real\n"
     ]
    }
   ],
   "source": [
    "# === IMPLEMENTAÃ‡ÃƒO CNN AVANÃ‡ADA BASEADA NO EEGNET ===\n",
    "class AdvancedEEGNet(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN avanÃ§ada baseada no EEGNet com melhorias especÃ­ficas para BCI\n",
    "    \n",
    "    Melhorias em relaÃ§Ã£o ao EEGNet bÃ¡sico:\n",
    "    - Spatial attention mechanism\n",
    "    - Multi-scale temporal convolutions\n",
    "    - Batch normalization adaptativo\n",
    "    - RegularizaÃ§Ã£o aprimorada\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_channels=16, n_classes=2, n_samples=400, \n",
    "                 dropout_rate=0.25, kernel_length=64, F1=8, D=2, F2=16):\n",
    "        super(AdvancedEEGNet, self).__init__()\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # ParÃ¢metros da arquitetura\n",
    "        self.kernel_length = kernel_length\n",
    "        self.F1 = F1\n",
    "        self.D = D\n",
    "        self.F2 = F2\n",
    "        \n",
    "        # === BLOCO 1: Multi-scale Temporal Convolution ===\n",
    "        # Filtros de diferentes escalas temporais\n",
    "        self.temporal_conv1 = nn.Conv2d(1, F1//2, (1, kernel_length), padding=(0, kernel_length // 2), bias=False)\n",
    "        self.temporal_conv2 = nn.Conv2d(1, F1//2, (1, kernel_length//2), padding=(0, kernel_length // 4), bias=False)\n",
    "        self.temporal_bn = nn.BatchNorm2d(F1)\n",
    "        \n",
    "        # === BLOCO 2: Spatial Attention + Depthwise Convolution ===\n",
    "        # Spatial attention\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(F1, F1//4, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(F1//4, F1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Depthwise convolution\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(F1, F1 * D, (n_channels, 1), groups=F1, bias=False),\n",
    "            nn.BatchNorm2d(F1 * D),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # === BLOCO 3: Enhanced Separable Convolution ===\n",
    "        self.separableConv = nn.Sequential(\n",
    "            # Depthwise\n",
    "            nn.Conv2d(F1 * D, F1 * D, (1, 16), padding=(0, 8), groups=F1 * D, bias=False),\n",
    "            # Pointwise\n",
    "            nn.Conv2d(F1 * D, F2, 1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # === BLOCO 4: Feature Enhancement ===\n",
    "        self.feature_enhancement = nn.Sequential(\n",
    "            nn.Conv2d(F2, F2*2, 1, bias=False),\n",
    "            nn.BatchNorm2d(F2*2),\n",
    "            nn.ELU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        # === CLASSIFICADOR AVANÃ‡ADO ===\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(F2*2, F2),\n",
    "            nn.BatchNorm1d(F2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(F2, n_classes)\n",
    "        )\n",
    "        \n",
    "        # InicializaÃ§Ã£o dos pesos\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "        print(f\"âœ… AdvancedEEGNet criado:\")\n",
    "        print(f\"   - Canais: {n_channels}\")\n",
    "        print(f\"   - Classes: {n_classes}\")\n",
    "        print(f\"   - Amostras: {n_samples}\")\n",
    "        print(f\"   - ParÃ¢metros: {sum(p.numel() for p in self.parameters()):,}\")\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"InicializaÃ§Ã£o dos pesos usando Xavier/He\"\"\"\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass com attention mechanism\n",
    "        Args:\n",
    "            x: tensor (batch_size, channels, samples) ou (batch_size, 1, channels, samples)\n",
    "        \"\"\"\n",
    "        # Garantir formato correto: (batch, 1, channels, samples)\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        # Bloco 1: Multi-scale temporal convolution\n",
    "        temp1 = self.temporal_conv1(x)\n",
    "        temp2 = self.temporal_conv2(x)\n",
    "        x = torch.cat([temp1, temp2], dim=1)  # Concatenar filtros multi-escala\n",
    "        x = self.temporal_bn(x)\n",
    "        \n",
    "        # Spatial attention\n",
    "        attention = self.spatial_attention(x)\n",
    "        x = x * attention  # Aplicar attention\n",
    "        \n",
    "        # Bloco 2: Depthwise convolution\n",
    "        x = self.depthwiseConv(x)\n",
    "        \n",
    "        # Bloco 3: Separable convolution\n",
    "        x = self.separableConv(x)\n",
    "        \n",
    "        # Bloco 4: Feature enhancement\n",
    "        x = self.feature_enhancement(x)\n",
    "        \n",
    "        # Classificador\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# === WRAPPER DE MODELO PERSONALIZADO ===\n",
    "class CustomEEGModel(nn.Module):\n",
    "    \"\"\"Wrapper para nosso modelo EEG personalizado\"\"\"\n",
    "    \n",
    "    def __init__(self, n_chans=16, n_outputs=2, n_times=400, sfreq=125.0, \n",
    "                 model_type='advanced', **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_chans = n_chans\n",
    "        self.n_outputs = n_outputs\n",
    "        self.n_times = n_times\n",
    "        self.sfreq = sfreq\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        # Escolher arquitetura\n",
    "        if model_type == 'advanced':\n",
    "            self.model = AdvancedEEGNet(\n",
    "                n_channels=n_chans,\n",
    "                n_classes=n_outputs,\n",
    "                n_samples=n_times,\n",
    "                dropout_rate=kwargs.get('dropout_rate', 0.25),\n",
    "                kernel_length=kwargs.get('kernel_length', 64),\n",
    "                F1=kwargs.get('F1', 8),\n",
    "                D=kwargs.get('D', 2),\n",
    "                F2=kwargs.get('F2', 16)\n",
    "            )\n",
    "            self.model_name = \"AdvancedEEGNet\"\n",
    "        else:  # basic\n",
    "            self.model = EEGNet(\n",
    "                n_channels=n_chans,\n",
    "                n_classes=n_outputs,\n",
    "                n_samples=n_times,\n",
    "                dropout_rate=kwargs.get('dropout_rate', 0.25),\n",
    "                kernel_length=kwargs.get('kernel_length', 64),\n",
    "                F1=kwargs.get('F1', 8),\n",
    "                D=kwargs.get('D', 2),\n",
    "                F2=kwargs.get('F2', 16)\n",
    "            )\n",
    "            self.model_name = \"EEGNet\"\n",
    "        \n",
    "        self.is_trained = False\n",
    "        \n",
    "        print(f\"âœ… Modelo {self.model_name} inicializado\")\n",
    "        print(f\"ðŸ“Š ParÃ¢metros totais: {sum(p.numel() for p in self.parameters()):,}\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def save_checkpoint(self, filepath, **kwargs):\n",
    "        \"\"\"Salvar checkpoint completo\"\"\"\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'model_type': self.model_name,\n",
    "            'constructor_args': {\n",
    "                'n_chans': self.n_chans,\n",
    "                'n_outputs': self.n_outputs,\n",
    "                'n_times': self.n_times,\n",
    "                'sfreq': self.sfreq,\n",
    "                'model_type': self.model_type\n",
    "            },\n",
    "            'is_trained': self.is_trained,\n",
    "            **kwargs\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        print(f\"âœ… Modelo salvo: {filepath}\")\n",
    "\n",
    "# === TESTE DOS MODELOS ===\n",
    "print(\"ðŸ§ª Testando modelos...\")\n",
    "\n",
    "# Teste modelo bÃ¡sico\n",
    "basic_model = CustomEEGModel(model_type='basic')\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(2, 16, 400)\n",
    "    test_output = basic_model(test_input)\n",
    "    print(f\"âœ… EEGNet BÃ¡sico: {test_input.shape} -> {test_output.shape}\")\n",
    "\n",
    "# Teste modelo avanÃ§ado\n",
    "advanced_model = CustomEEGModel(model_type='advanced')\n",
    "with torch.no_grad():\n",
    "    test_output_adv = advanced_model(test_input)\n",
    "    print(f\"âœ… EEGNet AvanÃ§ado: {test_input.shape} -> {test_output_adv.shape}\")\n",
    "\n",
    "# Comparar nÃºmero de parÃ¢metros\n",
    "basic_params = sum(p.numel() for p in basic_model.parameters())\n",
    "advanced_params = sum(p.numel() for p in advanced_model.parameters())\n",
    "\n",
    "print(f\"\\nðŸ“Š ComparaÃ§Ã£o de Modelos:\")\n",
    "print(f\"   - EEGNet BÃ¡sico: {basic_params:,} parÃ¢metros\")\n",
    "print(f\"   - EEGNet AvanÃ§ado: {advanced_params:,} parÃ¢metros\")\n",
    "print(f\"   - DiferenÃ§a: +{advanced_params - basic_params:,} parÃ¢metros\")\n",
    "\n",
    "# Limpar memÃ³ria\n",
    "del basic_model, advanced_model, test_input, test_output, test_output_adv\n",
    "\n",
    "print(\"\\nðŸŽ¯ Modelos EEGNet personalizados prontos para treinamento!\")\n",
    "print(\"âœ… ImplementaÃ§Ã£o 100% PyTorch sem dependÃªncias externas!\")\n",
    "\n",
    "# === EXECUÃ‡ÃƒO DO TREINAMENTO ===\n",
    "print(\"ðŸš€ INICIANDO TREINAMENTO...\")\n",
    "\n",
    "try:\n",
    "    results, trained_model = train_eegnet_model(windows, labels, subject_ids, training_params)\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ TREINAMENTO CONCLUÃDO!\")\n",
    "    print(f\"ðŸ“Š CV: {results['cv_mean']:.4f} Â± {results['cv_std']:.4f}\")\n",
    "    print(f\"ðŸŽ¯ Teste: {results['test_accuracy']:.4f}\")\n",
    "    \n",
    "    # Salvar modelo\n",
    "    if results['model_state_dict'] is not None:\n",
    "        model_name = f\"custom_eegnet_{int(time.time())}\"\n",
    "        model_path = MODELS_PATH / f\"{model_name}.pt\"\n",
    "        \n",
    "        save_model = CustomEEGModel(**results['model_params'])\n",
    "        save_model.load_state_dict(results['model_state_dict'])\n",
    "        save_model.is_trained = True\n",
    "        \n",
    "        save_model.save_checkpoint(\n",
    "            model_path,\n",
    "            test_accuracy=results['test_accuracy'],\n",
    "            cv_mean=results['cv_mean'],\n",
    "            cv_std=results['cv_std'],\n",
    "            normalization_stats=results['normalization_stats']\n",
    "        )\n",
    "        \n",
    "        print(f\"ðŸ’¾ Modelo salvo: {model_path}\")\n",
    "        \n",
    "        # Salvar info para referÃªncia\n",
    "        with open(PROJECT_ROOT / \"modelo_atual.txt\", 'w') as f:\n",
    "            f.write(f\"Modelo: {model_path.name}\\n\")\n",
    "            f.write(f\"CV: {results['cv_mean']:.4f} Â± {results['cv_std']:.4f}\\n\")\n",
    "            f.write(f\"Teste: {results['test_accuracy']:.4f}\\n\")\n",
    "            f.write(f\"Uso: python test_lsl_to_prediction_cycle.py\\n\")\n",
    "        \n",
    "        # VisualizaÃ§Ã£o simples\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar(['CV Mean', 'Test'], [results['cv_mean'], results['test_accuracy']], \n",
    "                color=['lightblue', 'lightgreen'])\n",
    "        plt.ylabel('AcurÃ¡cia')\n",
    "        plt.title('Performance do Modelo')\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        plt.pie(counts, labels=['MÃ£o Esquerda', 'MÃ£o Direita'], autopct='%1.1f%%')\n",
    "        plt.title('DistribuiÃ§Ã£o das Classes')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(RESULTS_PATH / f\"{model_name}_results.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"ðŸ“Š VisualizaÃ§Ã£o salva: {model_name}_results.png\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Modelo nÃ£o foi treinado com sucesso!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ERRO: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\nâœ… PIPELINE CONCLUÃDO!\")\n",
    "print(\"ðŸŽ¯ Para usar no sistema LSL:\")\n",
    "print(\"   1. Copie o caminho do modelo salvo\")\n",
    "print(\"   2. Execute: python test_lsl_to_prediction_cycle.py\")\n",
    "print(\"   3. Modelo compatÃ­vel com inferÃªncia em tempo real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9794978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ–¥ï¸ Device: cpu\n",
      "âœ… Modelo existente encontrado\n",
      "ðŸ“Š ParÃ¢metros do modelo: 16 canais, 400 amostras\n",
      "\n",
      "==================================================\n",
      "ARQUITETURA DO MODELO\n",
      "==================================================\n",
      "CustomEEGModel(\n",
      "  (model): AdvancedEEGNet(\n",
      "    (temporal_conv1): Conv2d(1, 4, kernel_size=(1, 64), stride=(1, 1), padding=(0, 32), bias=False)\n",
      "    (temporal_conv2): Conv2d(1, 4, kernel_size=(1, 32), stride=(1, 1), padding=(0, 16), bias=False)\n",
      "    (temporal_bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (spatial_attention): Sequential(\n",
      "      (0): Conv2d(8, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(2, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (3): Sigmoid()\n",
      "    )\n",
      "    (depthwiseConv): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(16, 1), stride=(1, 1), groups=8, bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
      "      (4): Dropout(p=0.25, inplace=False)\n",
      "    )\n",
      "    (separableConv): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), padding=(0, 8), groups=16, bias=False)\n",
      "      (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ELU(alpha=1.0)\n",
      "      (4): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "      (5): Dropout(p=0.25, inplace=False)\n",
      "    )\n",
      "    (feature_enhancement): Sequential(\n",
      "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (1): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "      (4): Dropout(p=0.25, inplace=False)\n",
      "      (5): Linear(in_features=16, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "ðŸ“ˆ ESTATÃSTICAS DO MODELO:\n",
      "   Total de parÃ¢metros: 2,444\n",
      "   ParÃ¢metros treinÃ¡veis: 2,444\n",
      "   ParÃ¢metros nÃ£o-treinÃ¡veis: 0\n",
      "   Status: âŒ NÃƒO TREINADO\n",
      "\n",
      "==================================================\n",
      "SUMÃRIO DETALHADO\n",
      "==================================================\n",
      "âš ï¸ Para obter um sumÃ¡rio detalhado, instale uma das bibliotecas:\n",
      "   pip install torchinfo   # (recomendado)\n",
      "   pip install torchsummary\n",
      "\n",
      "ðŸ“‹ SUMÃRIO MANUAL:\n",
      "   model.temporal_conv1: Conv2d - 256 parÃ¢metros\n",
      "   model.temporal_conv2: Conv2d - 128 parÃ¢metros\n",
      "   model.temporal_bn: BatchNorm2d - 16 parÃ¢metros\n",
      "   model.spatial_attention.0: Conv2d - 18 parÃ¢metros\n",
      "   model.spatial_attention.2: Conv2d - 24 parÃ¢metros\n",
      "   model.depthwiseConv.0: Conv2d - 256 parÃ¢metros\n",
      "   model.depthwiseConv.1: BatchNorm2d - 32 parÃ¢metros\n",
      "   model.separableConv.0: Conv2d - 256 parÃ¢metros\n",
      "   model.separableConv.1: Conv2d - 256 parÃ¢metros\n",
      "   model.separableConv.2: BatchNorm2d - 32 parÃ¢metros\n",
      "   model.feature_enhancement.0: Conv2d - 512 parÃ¢metros\n",
      "   model.feature_enhancement.1: BatchNorm2d - 64 parÃ¢metros\n",
      "   model.classifier.1: Linear - 528 parÃ¢metros\n",
      "   model.classifier.2: BatchNorm1d - 32 parÃ¢metros\n",
      "   model.classifier.5: Linear - 34 parÃ¢metros\n",
      "\n",
      "==================================================\n",
      "TESTE FORWARD PASS\n",
      "==================================================\n",
      "âœ… Teste bem-sucedido!\n",
      "   Input: torch.Size([2, 16, 400])\n",
      "   Output: torch.Size([2, 2])\n",
      "   Probabilidades (exemplo): [0.50132763 0.49867237]\n",
      "\n",
      "==================================================\n",
      "SUMÃRIO COMPLETO FINALIZADO\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CÃ©lula: SumÃ¡rio do Modelo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 0) Configurar device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ–¥ï¸ Device: {device}\")\n",
    "\n",
    "# 1) Verificar se modelo existe ou carregar/criar um\n",
    "if 'model' not in locals() and 'model' not in globals():\n",
    "    print(\"âš ï¸ Modelo nÃ£o encontrado. Criando opÃ§Ãµes...\")\n",
    "    \n",
    "    # OpÃ§Ã£o 1: Tentar carregar modelo salvo mais recente\n",
    "    MODELS_PATH = Path.cwd() / \"models\"\n",
    "    if MODELS_PATH.exists():\n",
    "        model_files = list(MODELS_PATH.glob(\"*.pt\"))\n",
    "        if model_files:\n",
    "            latest_model = max(model_files, key=os.path.getctime)\n",
    "            print(f\"ðŸ“ Modelo encontrado: {latest_model.name}\")\n",
    "            \n",
    "            try:\n",
    "                checkpoint = torch.load(latest_model, map_location=device)\n",
    "                \n",
    "                # Criar modelo baseado nos parÃ¢metros salvos\n",
    "                if 'constructor_args' in checkpoint:\n",
    "                    args = checkpoint['constructor_args']\n",
    "                    model = CustomEEGModel(**args)\n",
    "                    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                    model.to(device)\n",
    "                    print(f\"âœ… Modelo carregado: {latest_model.name}\")\n",
    "                else:\n",
    "                    raise ValueError(\"Checkpoint invÃ¡lido\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Erro ao carregar modelo: {e}\")\n",
    "                model = None\n",
    "        else:\n",
    "            print(\"ðŸ“ Nenhum modelo salvo encontrado\")\n",
    "            model = None\n",
    "    else:\n",
    "        print(\"ðŸ“ DiretÃ³rio de modelos nÃ£o encontrado\")\n",
    "        model = None\n",
    "    \n",
    "    # OpÃ§Ã£o 2: Criar modelo para demonstraÃ§Ã£o se nÃ£o conseguiu carregar\n",
    "    if model is None:\n",
    "        print(\"ðŸ› ï¸ Criando modelo de demonstraÃ§Ã£o...\")\n",
    "        model = CustomEEGModel(\n",
    "            n_chans=16,\n",
    "            n_outputs=2,\n",
    "            n_times=400,\n",
    "            sfreq=125.0,\n",
    "            model_type='advanced'\n",
    "        )\n",
    "        model.to(device)\n",
    "        print(\"âœ… Modelo de demonstraÃ§Ã£o criado\")\n",
    "\n",
    "else:\n",
    "    # Modelo jÃ¡ existe, apenas mover para device\n",
    "    model.to(device)\n",
    "    print(\"âœ… Modelo existente encontrado\")\n",
    "\n",
    "# 2) Capturar parÃ¢metros de forma genÃ©rica\n",
    "try:\n",
    "    n_channels = model.n_chans      # para CustomEEGModel\n",
    "    n_samples  = model.n_times\n",
    "    print(f\"ðŸ“Š ParÃ¢metros do modelo: {n_channels} canais, {n_samples} amostras\")\n",
    "except AttributeError:\n",
    "    try:\n",
    "        n_channels = model.n_channels\n",
    "        n_samples  = model.n_samples\n",
    "        print(f\"ðŸ“Š ParÃ¢metros do modelo: {n_channels} canais, {n_samples} amostras\")\n",
    "    except AttributeError:\n",
    "        n_channels = 16\n",
    "        n_samples  = 400\n",
    "        print(f\"ðŸ“Š Usando parÃ¢metros padrÃ£o: {n_channels} canais, {n_samples} amostras\")\n",
    "\n",
    "# 3) Imprimir arquitetura do modelo\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ARQUITETURA DO MODELO\")\n",
    "print(\"=\"*50)\n",
    "print(model)\n",
    "\n",
    "# 4) Contagem de parÃ¢metros\n",
    "total_params     = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nðŸ“ˆ ESTATÃSTICAS DO MODELO:\")\n",
    "print(f\"   Total de parÃ¢metros: {total_params:,}\")\n",
    "print(f\"   ParÃ¢metros treinÃ¡veis: {trainable_params:,}\")\n",
    "print(f\"   ParÃ¢metros nÃ£o-treinÃ¡veis: {total_params - trainable_params:,}\")\n",
    "\n",
    "# 5) Verificar se modelo foi treinado\n",
    "if hasattr(model, 'is_trained'):\n",
    "    status = \"âœ… TREINADO\" if model.is_trained else \"âŒ NÃƒO TREINADO\"\n",
    "    print(f\"   Status: {status}\")\n",
    "\n",
    "# 6) SumÃ¡rio detalhado usando torchinfo ou torchsummary\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"SUMÃRIO DETALHADO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary as info_summary\n",
    "    print(\"Usando torchinfo...\")\n",
    "    info_summary(model, input_size=(1, n_channels, n_samples), device=device)\n",
    "except ImportError:\n",
    "    try:\n",
    "        from torchsummary import summary as ts_summary\n",
    "        print(\"Usando torchsummary...\")\n",
    "        ts_summary(model, input_size=(n_channels, n_samples))\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ Para obter um sumÃ¡rio detalhado, instale uma das bibliotecas:\")\n",
    "        print(\"   pip install torchinfo   # (recomendado)\")\n",
    "        print(\"   pip install torchsummary\")\n",
    "        \n",
    "        # SumÃ¡rio manual bÃ¡sico\n",
    "        print(\"\\nðŸ“‹ SUMÃRIO MANUAL:\")\n",
    "        for name, module in model.named_modules():\n",
    "            if len(list(module.children())) == 0:  # Apenas camadas folha\n",
    "                params = sum(p.numel() for p in module.parameters())\n",
    "                if params > 0:\n",
    "                    print(f\"   {name}: {module.__class__.__name__} - {params:,} parÃ¢metros\")\n",
    "\n",
    "# 7) Teste forward pass\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"TESTE FORWARD PASS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_input = torch.randn(2, n_channels, n_samples).to(device)\n",
    "        test_output = model(test_input)\n",
    "        print(f\"âœ… Teste bem-sucedido!\")\n",
    "        print(f\"   Input: {test_input.shape}\")\n",
    "        print(f\"   Output: {test_output.shape}\")\n",
    "        print(f\"   Probabilidades (exemplo): {torch.softmax(test_output[0], dim=0).cpu().numpy()}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro no teste: {e}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"SUMÃRIO COMPLETO FINALIZADO\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
